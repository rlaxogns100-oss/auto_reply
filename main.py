import time
import random
import platform
import urllib.parse 
import os 
import json
import requests
import signal
import sys
import pickle
import copy
from datetime import datetime, timezone, timedelta
import google.generativeai as genai
from openai import AzureOpenAI
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import UnexpectedAlertPresentException, NoAlertPresentException
import config

# ==========================================
# [DRY RUN ëª¨ë“œ]
# ==========================================
# í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´: DRY_RUN=trueë©´ ëŒ“ê¸€ì„ ì‹¤ì œë¡œ ë‹¬ì§€ ì•Šê³  ìƒì„±ë§Œ í•¨
DRY_RUN = os.environ.get("DRY_RUN", "false").lower() == "true"

# ==========================================
# [ì„œë²„ìš© ì„¤ì •]
# ==========================================
# ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

# ì¹´í˜ë³„ ë””ë ‰í† ë¦¬ (í™˜ê²½ë³€ìˆ˜ë¡œ ì „ë‹¬ë°›ìŒ, ì—†ìœ¼ë©´ SCRIPT_DIR ì‚¬ìš©)
CAFE_DIR = os.environ.get("CAFE_DIR", SCRIPT_DIR)
CAFE_ID = os.environ.get("CAFE_ID", "suhui")

# ì¹´í˜ë³„ config ë¡œë“œ
if CAFE_DIR != SCRIPT_DIR:
    # cafes/{cafe_id}/config.pyì—ì„œ ì„¤ì • ë¡œë“œ
    cafe_config_path = os.path.join(CAFE_DIR, "config.py")
    if os.path.exists(cafe_config_path):
        import importlib.util
        spec = importlib.util.spec_from_file_location("cafe_config", cafe_config_path)
        cafe_config = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(cafe_config)
        # config ëª¨ë“ˆì˜ ê°’ë“¤ì„ ë®ì–´ì“°ê¸°
        for attr in ['NAVER_ID', 'NAVER_PW', 'GEMINI_API_KEY', 'CLUB_ID', 'CAFE_NAME', 'CAFE_URL', 'CAFE_MENU_IDS']:
            if hasattr(cafe_config, attr):
                setattr(config, attr, getattr(cafe_config, attr))
        print(f"[ë´‡] ì¹´í˜ ì„¤ì • ë¡œë“œ: {CAFE_ID} ({getattr(config, 'CAFE_NAME', 'unknown')})")

# íŒŒì¼ ê²½ë¡œëŠ” ì¹´í˜ë³„ ë””ë ‰í† ë¦¬ ì‚¬ìš©
# ì¿ í‚¤ íŒŒì¼ì€ í™˜ê²½ë³€ìˆ˜ë¡œ ì „ë‹¬ë°›ê±°ë‚˜ ì¹´í˜ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ìŒ
COOKIE_FILE = os.environ.get("COOKIE_FILE", os.path.join(CAFE_DIR, "naver_cookies.pkl"))
BOT_CONFIG_FILE = os.path.join(CAFE_DIR, "bot_config.json")
BOT_PROMPTS_FILE = os.path.join(CAFE_DIR, "bot_prompts.json")
COMMENT_HISTORY_FILE = os.path.join(CAFE_DIR, "comment_history.json")
DRY_RUN_HISTORY_FILE = os.path.join(CAFE_DIR, "dry_run_history.json")
SKIP_LINKS_FILE = os.path.join(CAFE_DIR, "skip_links.json")
TRAINING_EXAMPLES_FILE = os.path.join(CAFE_DIR, "training_examples.json")
STOP_FLAG_FILE = os.path.join(CAFE_DIR, ".stop_bot")

# ê³„ì • ID (ë¡œê·¸ìš©)
ACCOUNT_ID = os.environ.get("ACCOUNT_ID", "unknown")
print(f"[ë´‡] ê³„ì •: {ACCOUNT_ID}, ì¿ í‚¤: {COOKIE_FILE}")

# Headless ëª¨ë“œ (ì„œë²„ìš©)
HEADLESS_MODE = os.environ.get("HEADLESS", "true").lower() == "true"

# ë´‡ ì¢…ë£Œ í”Œë˜ê·¸
should_stop = False

def signal_handler(signum, frame):
    """SIGTERM/SIGINT ì‹œê·¸ë„ ì²˜ë¦¬"""
    global should_stop
    print("\n[ë´‡] ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ , ì•ˆì „í•˜ê²Œ ì¢…ë£Œ ì¤‘...")
    should_stop = True

signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)

def check_stop_flag():
    """ì •ì§€ í”Œë˜ê·¸ íŒŒì¼ í™•ì¸"""
    if os.path.exists(STOP_FLAG_FILE):
        os.remove(STOP_FLAG_FILE)
        return True
    return False


def load_query_prompt():
    """bot_prompts.jsonì—ì„œ Query Agent í”„ë¡¬í”„íŠ¸ ë¡œë“œ. ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’."""
    if os.path.exists(BOT_PROMPTS_FILE):
        try:
            with open(BOT_PROMPTS_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                p = (data.get("query_prompt") or "").strip()
                if p:
                    return p
        except Exception:
            pass
    return DEFAULT_QUERY_PROMPT

def load_answer_prompt():
    """bot_prompts.jsonì—ì„œ Answer Agent í”„ë¡¬í”„íŠ¸ ë¡œë“œ. ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’."""
    if os.path.exists(BOT_PROMPTS_FILE):
        try:
            with open(BOT_PROMPTS_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                p = (data.get("answer_prompt") or "").strip()
                if p:
                    return p
        except Exception:
            pass
    return DEFAULT_ANSWER_PROMPT.strip()


def load_training_examples():
    """training_examples.jsonì—ì„œ í•™ìŠµ ì˜ˆì‹œ ë¡œë“œ"""
    if os.path.exists(TRAINING_EXAMPLES_FILE):
        try:
            with open(TRAINING_EXAMPLES_FILE, "r", encoding="utf-8") as f:
                examples = json.load(f)
                return examples
        except Exception as e:
            print(f"  -> [í•™ìŠµ ë°ì´í„°] ë¡œë“œ ì‹¤íŒ¨: {e}")
    return []


def format_training_examples(examples, max_examples=78):
    """í•™ìŠµ ì˜ˆì‹œë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ… (ì „ì²´ 78ê°œ ì‚¬ìš©)"""
    if not examples:
        return ""
    
    # ì „ì²´ ì‚¬ìš© (78ê°œ ì´í•˜ë©´ ì „ë¶€, ì´ˆê³¼í•˜ë©´ ëœë¤ ì„ íƒ)
    if len(examples) <= max_examples:
        selected = examples
    else:
        selected = random.sample(examples, max_examples)
    
    formatted_parts = []
    for i, ex in enumerate(selected, 1):
        title = ex.get("post_title", "")
        comment = ex.get("output_comment", "")
        if title and comment and len(comment) > 30:
            formatted_parts.append(f"[ì˜ˆì‹œ {i}]\nì§ˆë¬¸: {title}\në‹µë³€: {comment}")
    
    return "\n\n".join(formatted_parts)


# ==========================================
# [í•™ìŠµ ë°ì´í„°] comment_history.jsonì—ì„œ ì‹¤ì‹œê°„ ë¡œë“œ
# ==========================================
# í•™ìŠµ ë°ì´í„° ê³µìœ  ì¹´í˜ ëª©ë¡ (ìˆ˜ë§Œíœ˜, ìˆ˜í—˜ìƒì¹´í˜, ë§˜ì¹´í˜)
SHARED_TRAINING_CAFES = ["suhui", "pnmath", "gangmok"]

def load_comment_history_for_training():
    """
    ì—¬ëŸ¬ ì¹´í˜ì˜ comment_history.jsonì—ì„œ í•™ìŠµìš© ë°ì´í„° ë¡œë“œ (ì›ë³¸ í›¼ì† ì—†ì´ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©)
    - ìˆ˜ë§Œíœ˜, ìˆ˜í—˜ìƒì¹´í˜, ë§˜ì¹´í˜ì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ê³µìœ í•˜ì—¬ ì‚¬ìš©
    """
    all_history = []
    cafes_dir = os.path.join(SCRIPT_DIR, "cafes")
    
    for cafe_id in SHARED_TRAINING_CAFES:
        history_file = os.path.join(cafes_dir, cafe_id, "comment_history.json")
        if not os.path.exists(history_file):
            continue
        
        try:
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
            # ì›ë³¸ í›¼ì† ë°©ì§€: ê¹Šì€ ë³µì‚¬ í›„ ì¶”ê°€
            all_history.extend(copy.deepcopy(history))
        except Exception as e:
            print(f"  -> [í•™ìŠµ ë°ì´í„°] {cafe_id} comment_history ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue
    
    print(f"  -> [í•™ìŠµ ë°ì´í„°] ì´ {len(all_history)}ê°œ ë¡œë“œ (ì¹´í˜: {', '.join(SHARED_TRAINING_CAFES)})")
    return all_history


def get_answer_agent_examples(max_good=5, max_bad=5):
    """
    Answer Agentìš© í•™ìŠµ ì˜ˆì‹œ ê°€ì ¸ì˜¤ê¸°
    - ì¢‹ì€ ì˜ˆì‹œ: ê²Œì‹œì™„ë£Œ(posted), ìŠ¹ì¸ë¨(approved) ì¤‘ ëœë¤ 5ê°œ
    - ë‚˜ìœ ì˜ˆì‹œ: ì·¨ì†Œë¨(cancelled) ì¤‘ cancel_reasonì´ 'ìµœì¢…ë‹µë³€ë¶€ì‹¤'ì¸ ê²ƒë§Œ ëœë¤ 5ê°œ
    - intro/outroëŠ” ì œê±°í•˜ê³  ë³¸ë¬¸ë§Œ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©
    
    Returns:
        tuple: (good_examples, bad_examples)
    """
    history = load_comment_history_for_training()
    
    def strip_intro_outro(comment):
        """ëŒ“ê¸€ì—ì„œ intro(ì²« ì¤„)ì™€ outro(ë§ˆì§€ë§‰ ì¤„)ë¥¼ ì œê±°í•˜ê³  ë³¸ë¬¸ë§Œ ë°˜í™˜"""
        if not comment:
            return comment
        
        # ë¹ˆ ì¤„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        paragraphs = comment.strip().split('\n\n')
        
        # 3ê°œ ì´ìƒì˜ ë‹¨ë½ì´ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ì œê±°
        if len(paragraphs) >= 3:
            # ì¤‘ê°„ ë‹¨ë½ë“¤ë§Œ ë°˜í™˜
            return '\n\n'.join(paragraphs[1:-1])
        elif len(paragraphs) == 2:
            # 2ê°œë©´ ì²« ë²ˆì§¸ë§Œ ì œê±° (ë§ˆì§€ë§‰ì€ ë³¸ë¬¸ì¼ ìˆ˜ ìˆìŒ)
            return paragraphs[1]
        else:
            # 1ê°œë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return comment
    
    # ìƒíƒœë³„ ë¶„ë¥˜
    good_examples = []  # posted, approved
    bad_examples = []   # cancelled with reason 'ìµœì¢…ë‹µë³€ë¶€ì‹¤'
    
    for item in history:
        status = item.get("status", "")
        cancel_reason = item.get("cancel_reason", "")
        post_content = item.get("post_content", "") or item.get("post_title", "")
        comment = item.get("comment", "")
        
        if not post_content or not comment:
            continue
        
        # intro/outro ì œê±°í•œ ë³¸ë¬¸ë§Œ ì‚¬ìš©
        comment_body = strip_intro_outro(comment)
        
        example = {
            "post_content": post_content[:500],  # ì›ê¸€ (500ì ì œí•œ)
            "comment": comment_body  # ìµœì¢…ë‹µë³€ (intro/outro ì œê±°)
        }
        
        if status in ["posted", "approved"]:
            good_examples.append(example)
        elif status == "cancelled" and cancel_reason == "ìµœì¢…ë‹µë³€ë¶€ì‹¤":
            # ë‚˜ìœ ì˜ˆì‹œëŠ” 'ìµœì¢…ë‹µë³€ë¶€ì‹¤' ì‚¬ìœ ê°€ ìˆëŠ” ê²ƒë§Œ
            bad_examples.append(example)
    
    # ëœë¤ ì„ íƒ
    selected_good = random.sample(good_examples, min(max_good, len(good_examples))) if good_examples else []
    selected_bad = random.sample(bad_examples, min(max_bad, len(bad_examples))) if bad_examples else []
    
    print(f"  -> [í•™ìŠµ ë°ì´í„°] ì¢‹ì€ ì˜ˆì‹œ {len(selected_good)}ê°œ, ë‚˜ìœ ì˜ˆì‹œ(ìµœì¢…ë‹µë³€ë¶€ì‹¤) {len(selected_bad)}ê°œ ë¡œë“œ (intro/outro ì œê±°ë¨)")
    
    return selected_good, selected_bad


def format_answer_agent_examples(good_examples, bad_examples):
    """Answer Agentìš© í•™ìŠµ ì˜ˆì‹œë¥¼ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
    parts = []
    
    # ì¢‹ì€ ì˜ˆì‹œ (ë”°ë¼í•´ì•¼ í•  ê²ƒ)
    if good_examples:
        parts.append("=" * 50)
        parts.append("[âœ… ë”°ë¼í•´ì•¼ í•  ì¢‹ì€ ë‹µë³€ ì˜ˆì‹œ]")
        parts.append("ì•„ë˜ëŠ” ìŠ¹ì¸ë˜ì–´ ì‹¤ì œë¡œ ê²Œì‹œëœ ë‹µë³€ì…ë‹ˆë‹¤.")
        parts.append("íŠ¹ì§•: 3~4ë¬¸ì¥, êµ¬ì²´ì ì¸ ìˆ«ì(ì…ê²°, ëª¨ì§‘ì¸ì› ë“±) ì¸ìš©, ~í•´ìš”ì²´")
        parts.append("=" * 50)
        for i, ex in enumerate(good_examples, 1):
            parts.append(f"\n[ì¢‹ì€ ì˜ˆì‹œ {i}]")
            parts.append(f"ì›ê¸€: {ex['post_content']}")
            parts.append(f"ë‹µë³€: {ex['comment']}")
    
    # ë‚˜ìœ ì˜ˆì‹œ (ë”°ë¼í•˜ë©´ ì•ˆ ë˜ëŠ” ê²ƒ)
    if bad_examples:
        parts.append("\n" + "=" * 50)
        parts.append("[âŒ ë”°ë¼í•˜ë©´ ì•ˆ ë˜ëŠ” ë‚˜ìœ ë‹µë³€ ì˜ˆì‹œ]")
        parts.append("ì•„ë˜ëŠ” ì·¨ì†Œëœ ë‹µë³€ì…ë‹ˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.")
        parts.append("ë¬¸ì œì : ë„ˆë¬´ ê¹€, ë§ˆí¬ë‹¤ìš´ ì‚¬ìš©, ë²ˆí˜¸ ëª©ë¡ ì‚¬ìš©, RAG ë°ì´í„° ì—†ì´ ì¼ë°˜ì  ì¡°ì–¸")
        parts.append("=" * 50)
        for i, ex in enumerate(bad_examples, 1):
            parts.append(f"\n[ë‚˜ìœ ì˜ˆì‹œ {i}]")
            parts.append(f"ì›ê¸€: {ex['post_content']}")
            parts.append(f"ë‹µë³€: {ex['comment']}")
    
    return "\n".join(parts)


def get_query_agent_examples(max_examples=10):
    """
    Query Agentìš© í•™ìŠµ ì˜ˆì‹œ ê°€ì ¸ì˜¤ê¸°
    - ì·¨ì†Œë¨(cancelled) ì¤‘ cancel_reasonì´ 'ë¶€ì ì ˆí•œ ê¸€'ì¸ ê²ƒ ëœë¤ 10ê°œ
    - ì›ê¸€ë§Œ ì „ë‹¬ (ì´ëŸ° ê¸€ì—ëŠ” ë‹µë³€í•˜ì§€ ë§ë¼ëŠ” ì˜ë¯¸)
    
    Returns:
        list: ë¶€ì ì ˆí•œ ê¸€ ì˜ˆì‹œ ëª©ë¡
    """
    history = load_comment_history_for_training()
    
    inappropriate_posts = []
    
    for item in history:
        status = item.get("status", "")
        cancel_reason = item.get("cancel_reason", "")
        post_content = item.get("post_content", "") or item.get("post_title", "")
        
        if status == "cancelled" and cancel_reason == "ë¶€ì ì ˆí•œ ê¸€" and post_content:
            inappropriate_posts.append({
                "post_content": post_content[:500]  # ì›ê¸€ (500ì ì œí•œ)
            })
    
    # ëœë¤ ì„ íƒ
    selected = random.sample(inappropriate_posts, min(max_examples, len(inappropriate_posts))) if inappropriate_posts else []
    
    print(f"  -> [Query Agent í•™ìŠµ] ë¶€ì ì ˆí•œ ê¸€ ì˜ˆì‹œ {len(selected)}ê°œ ë¡œë“œ")
    
    return selected


def format_query_agent_examples(inappropriate_posts):
    """Query Agentìš© í•™ìŠµ ì˜ˆì‹œë¥¼ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
    if not inappropriate_posts:
        return ""
    
    parts = []
    parts.append("\n" + "=" * 50)
    parts.append("[âŒ ë‹µë³€í•˜ë©´ ì•ˆ ë˜ëŠ” ë¶€ì ì ˆí•œ ê¸€ ì˜ˆì‹œ]")
    parts.append("ì•„ë˜ì™€ ê°™ì€ ê¸€ì—ëŠ” PASS ì²˜ë¦¬í•˜ì„¸ìš”. (ë¹ˆ ë°°ì—´ ë°˜í™˜)")
    parts.append("=" * 50)
    
    for i, ex in enumerate(inappropriate_posts, 1):
        parts.append(f"\n[ë¶€ì ì ˆí•œ ê¸€ {i}]")
        parts.append(f"ì›ê¸€: {ex['post_content']}")
    
    return "\n".join(parts)


def load_bot_config():
    """ë´‡ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    default_config = {
        "min_delay_seconds": 50,
        "comments_per_hour_min": 5,
        "comments_per_hour_max": 10,
        "rest_minutes": 3
    }
    if os.path.exists(BOT_CONFIG_FILE):
        try:
            with open(BOT_CONFIG_FILE, "r", encoding="utf-8") as f:
                loaded = json.load(f)
                default_config.update(loaded)
        except:
            pass
    return default_config

def save_comment_history(post_url, post_title, comment_content, success=True,
                         post_content=None, query=None, function_result=None,
                         status="pending", comment_id=None):
    """ëŒ“ê¸€ ê¸°ë¡ ì €ì¥ (ë°˜ìë™ ì‹œìŠ¤í…œìš©)
    
    Args:
        status: pending(ëŒ€ê¸°ì¤‘), approved(ìŠ¹ì¸ë¨), cancelled(ì·¨ì†Œë¨), posted(ê²Œì‹œì™„ë£Œ)
        comment_id: ê³ ìœ  ID (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
    """
    import uuid
    
    # ê°€ì‹¤í–‰ ëª¨ë“œëŠ” ë³„ë„ íŒŒì¼ì— ê¸°ë¡
    if DRY_RUN:
        history_file = DRY_RUN_HISTORY_FILE
    else:
        history_file = COMMENT_HISTORY_FILE
    
    history = []
    if os.path.exists(history_file):
        try:
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
        except:
            history = []
    
    now = datetime.now().isoformat()
    record = {
        "id": comment_id or str(uuid.uuid4()),
        "timestamp": now,
        "post_url": post_url,
        "post_title": post_title,
        "comment": comment_content,
        "success": success,
        "dry_run": DRY_RUN,
        "status": status,
        "action_history": [{"action": "created", "timestamp": now}],
        "posted_at": None
    }
    if post_content is not None:
        record["post_content"] = post_content
    if query is not None:
        record["query"] = query
    if function_result is not None:
        record["function_result"] = function_result
    history.append(record)
    
    # ìµœê·¼ 500ê°œë§Œ ìœ ì§€
    if len(history) > 500:
        history = history[-500:]
    
    with open(history_file, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)
    
    return record["id"]

def load_cookies(driver):
    """ì¿ í‚¤ íŒŒì¼ë¡œ ë¡œê·¸ì¸"""
    if not os.path.exists(COOKIE_FILE):
        print(f"[ì—ëŸ¬] ì¿ í‚¤ íŒŒì¼ ì—†ìŒ: {COOKIE_FILE}")
        print("[ì•ˆë‚´] ë¡œì»¬ì—ì„œ get_cookies.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì¿ í‚¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return False
    
    try:
        driver.get("https://naver.com")
        time.sleep(2)
        
        with open(COOKIE_FILE, "rb") as f:
            cookies = pickle.load(f)
        
        for cookie in cookies:
            # ì¼ë¶€ ì¿ í‚¤ ì†ì„± ì œê±° (í˜¸í™˜ì„±)
            if 'expiry' in cookie:
                del cookie['expiry']
            try:
                driver.add_cookie(cookie)
            except:
                pass
        
        driver.refresh()
        time.sleep(2)
        
        # ë¡œê·¸ì¸ í™•ì¸
        page_source = driver.page_source
        if "ë¡œê·¸ì•„ì›ƒ" in page_source or "ë‚´ì •ë³´" in page_source or "MY" in page_source:
            print("[ë´‡] ì¿ í‚¤ ë¡œê·¸ì¸ ì„±ê³µ!")
            return True
        else:
            print("[ì—ëŸ¬] ì¿ í‚¤ ë§Œë£Œë¨. ë‹¤ì‹œ ì¶”ì¶œí•˜ì„¸ìš”.")
            return False
            
    except Exception as e:
        print(f"[ì—ëŸ¬] ì¿ í‚¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

# ==========================================
# [ì„¤ì •] AI ëª¨ë¸ ë° API í‚¤
# ==========================================
HISTORY_FILE = os.path.join(CAFE_DIR, "visited_history.txt")

# AI ëª¨ë¸ ì œê³µì ì„¤ì • (gemini ë˜ëŠ” azure)
AI_MODEL_PROVIDER = getattr(config, 'AI_MODEL_PROVIDER', 'gemini')

# Azure OpenAI ì„¤ì • (config.py ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
AZURE_OPENAI_ENDPOINT = getattr(config, 'AZURE_OPENAI_ENDPOINT', '') or os.getenv('AZURE_OPENAI_ENDPOINT', '')
AZURE_OPENAI_API_KEY = getattr(config, 'AZURE_OPENAI_API_KEY', '') or os.getenv('AZURE_OPENAI_API_KEY', '')
AZURE_OPENAI_API_VERSION = getattr(config, 'AZURE_OPENAI_API_VERSION', '2024-02-15-preview')
AZURE_OPENAI_DEPLOYMENT = getattr(config, 'AZURE_OPENAI_DEPLOYMENT', 'gpt-5.2-chat-4')

# bot_config.jsonì—ì„œ ëª¨ë¸ ì„¤ì • ë¡œë“œ (ëŸ°íƒ€ì„ ë³€ê²½ ì§€ì›)
def load_model_config():
    """bot_config.jsonì—ì„œ AI ëª¨ë¸ ì„¤ì • ë¡œë“œ"""
    global AI_MODEL_PROVIDER
    if os.path.exists(BOT_CONFIG_FILE):
        try:
            with open(BOT_CONFIG_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                provider = data.get("ai_model_provider", "").strip()
                if provider in ["gemini", "azure"]:
                    return provider
        except Exception:
            pass
    return AI_MODEL_PROVIDER

# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
azure_client = None
if AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY:
    try:
        azure_client = AzureOpenAI(
            azure_endpoint=AZURE_OPENAI_ENDPOINT,
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION
        )
        print(f"[INFO] Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ë°°í¬: {AZURE_OPENAI_DEPLOYMENT})")
    except Exception as e:
        print(f"[WARNING] Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        azure_client = None

# Gemini API ì„¤ì •
genai.configure(api_key=config.GEMINI_API_KEY)

# Query Agent (RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±ìš©)
query_agent_gemini = None
try:
    query_agent_gemini = genai.GenerativeModel('gemini-2.5-flash-lite')
    print("[INFO] Query Agent (Gemini): gemini-2.5-flash-lite")
except:
    try:
        query_agent_gemini = genai.GenerativeModel('gemini-2.0-flash')
        print("[INFO] Query Agent (Gemini): gemini-2.0-flash (fallback)")
    except:
        print("[WARNING] Gemini Query Agent ì´ˆê¸°í™” ì‹¤íŒ¨")

# Answer Agent (ë‹µë³€ ìƒì„±ìš©)
answer_agent_gemini = None
try:
    answer_agent_gemini = genai.GenerativeModel('gemini-2.5-flash-lite')
    print("[INFO] Answer Agent (Gemini): gemini-2.5-flash-lite")
except:
    try:
        answer_agent_gemini = genai.GenerativeModel('gemini-2.0-flash')
        print("[INFO] Answer Agent (Gemini): gemini-2.0-flash (fallback)")
    except:
        print("[WARNING] Gemini Answer Agent ì´ˆê¸°í™” ì‹¤íŒ¨")

# í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ í‘œì‹œ
current_provider = load_model_config()
print(f"[INFO] í˜„ì¬ AI ëª¨ë¸ ì œê³µì: {current_provider.upper()}")


def call_ai_model(prompt, is_json_response=False, temperature=0.3, max_tokens=2048):
    """
    AI ëª¨ë¸ í˜¸ì¶œ (Gemini ë˜ëŠ” Azure OpenAI)
    
    Args:
        prompt: í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        is_json_response: JSON ì‘ë‹µ ì—¬ë¶€ (Query Agentìš©)
        temperature: ì˜¨ë„ ì„¤ì •
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
    
    Returns:
        str: AI ì‘ë‹µ í…ìŠ¤íŠ¸
        None: ì—ëŸ¬ ë°œìƒ ì‹œ
    """
    provider = load_model_config()
    
    if provider == "azure" and azure_client:
        try:
            messages = [{"role": "user", "content": prompt}]
            
            response = azure_client.chat.completions.create(
                model=AZURE_OPENAI_DEPLOYMENT,
                messages=messages,
                temperature=temperature,
                max_completion_tokens=max_tokens,
                response_format={"type": "json_object"} if is_json_response else None
            )
            
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"  -> [Azure OpenAI ì—ëŸ¬] {e}")
            # Fallback to Gemini
            if query_agent_gemini or answer_agent_gemini:
                print("  -> [Fallback] Geminië¡œ ì „í™˜...")
                provider = "gemini"
            else:
                return None
    
    if provider == "gemini":
        try:
            agent = query_agent_gemini if is_json_response else answer_agent_gemini
            if not agent:
                print("  -> [ì—ëŸ¬] Gemini ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return None
            
            generation_config = {
                "temperature": temperature,
                "max_output_tokens": max_tokens
            }
            if is_json_response:
                generation_config["response_mime_type"] = "application/json"
            
            response = agent.generate_content(prompt, generation_config=generation_config)
            return (response.text or "").strip()
        except Exception as e:
            print(f"  -> [Gemini ì—ëŸ¬] {e}")
            return None
    
    print(f"  -> [ì—ëŸ¬] ì•Œ ìˆ˜ ì—†ëŠ” AI ì œê³µì: {provider}")
    return None


# ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³€ìˆ˜ (ê¸°ì¡´ ì½”ë“œì—ì„œ ì‚¬ìš©)
query_agent = query_agent_gemini
answer_agent = answer_agent_gemini

# ê¸°ë³¸ í‚¤ì›Œë“œ (bot_config.jsonì— ì—†ì„ ë•Œ ì‚¬ìš©)
DEFAULT_KEYWORDS = [
    # 1. [í•µì‹¬] ì •ì‹œ íŒŒì´í„°ë“¤ì˜ ê³µí†µ ì–¸ì–´ (ê°€ì¥ ì¤‘ìš”)
    "ì •ì‹œ", "í‘œì ", "í‘œì¤€ì ìˆ˜", "í™˜ì‚°ì ìˆ˜", "ë°±ë¶„ìœ„",
    "ì¶”í•©", "ì˜ˆë¹„", "ìµœì´ˆí•©", "ì „ì°¬", "ì¶”ê°€í•©ê²©",
    "ìƒí–¥", "ì†Œì‹ ", "ì•ˆì •", "í•˜í–¥", "ìŠ¤ë‚˜", "ë¹µê¾¸", # 'ìŠ¤ë‚˜', 'ë¹µê¾¸'ëŠ” ê¸°íšŒë¥¼ ë…¸ë¦¬ëŠ” ì€ì–´

    # 2. [í™•ì¥] ëŒ€í•™ ë¼ì¸ (ì¤‘ìœ„ê¶Œ~ì¸ì„œìš¸ ì „ì²´ë¡œ í™•ì¥)
    "ì¸ì„œìš¸", "ìˆ˜ë„ê¶Œ", "ì§€ê±°êµ­", "ëŒ€í•™ ë¼ì¸", "ì–´ë””ê°€",
    "ê±´ë™í™", "êµ­ìˆ­ì„¸ë‹¨", "ê´‘ëª…ìƒê°€", "ì¸ê°€ê²½", "í•œì„œì‚¼", # í•™ìƒë“¤ì´ ê°€ì¥ ë§ì´ ê³ ë¯¼í•˜ëŠ” ë¼ì¸

    # 3. [ëŒ€í•™ëª…]
    "ì„œìš¸ëŒ€", "ì—°ì„¸ëŒ€", "ê³ ë ¤ëŒ€", "ì„±ê· ê´€ëŒ€", "í•œì–‘ëŒ€",
    "ì¤‘ì•™ëŒ€", "ê±´êµ­ëŒ€", "í•œêµ­ì™¸ëŒ€", "ì¤‘ëŒ€", "ê²½í¬ëŒ€",
    "ë™êµ­ëŒ€", "ëª…ì§€ëŒ€", "ì„œê°•ëŒ€", "ê´‘ìš´ëŒ€", "ì„ ë¦¬ëŒ€",
    "ìˆ­ì‹¤ëŒ€", "ì´í™”ì—¬ëŒ€"      

    # 3. ê¸°íƒ€ í‚¤ì›Œë“œ
    "ê¹Œìš”", "vs", "ê°€ëŠ¥", "ì–´ë””", "ë´ì£¼", "ì¡°ì–¸", "ìƒë‹´"
]

def load_keywords():
    """bot_config.jsonì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ë¡œë“œ. ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©."""
    if os.path.exists(BOT_CONFIG_FILE):
        try:
            with open(BOT_CONFIG_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                keywords = data.get("keywords", [])
                if keywords and len(keywords) > 0:
                    return keywords
        except Exception:
            pass
    return DEFAULT_KEYWORDS


def load_banned_keywords():
    """bot_config.jsonì—ì„œ ê¸ˆì§€ í‚¤ì›Œë“œ ë¡œë“œ. ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    if os.path.exists(BOT_CONFIG_FILE):
        try:
            with open(BOT_CONFIG_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("banned_keywords", [])
        except Exception:
            pass
    return []


def contains_banned_keyword(title, content, banned_keywords):
    """ì œëª©ì´ë‚˜ ë³¸ë¬¸ì— ê¸ˆì§€ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    if not banned_keywords:
        return False
    
    text = (title or "") + " " + (content or "")
    text = text.lower()
    
    for keyword in banned_keywords:
        if keyword.lower() in text:
            return True
    return False

# Backend API URL (configì—ì„œ ê°€ì ¸ì˜¤ê¸°, ê¸°ë³¸ê°’: ë¡œì»¬)
BACKEND_URL = getattr(config, 'BACKEND_URL', 'http://localhost:8000')

# ==========================================
# [ì˜¤í”„ë‹/í´ë¡œì§• ë©˜íŠ¸] ëœë¤ ì„ íƒ
# ==========================================

# ì˜¤í”„ë‹: "AIí•œí…Œ ë¬¼ì–´ë³´ë‹ˆê¹Œ ì´ë ‡ë‹¤" (ì´ˆê°„ë‹¨ ë²„ì „)
OPENINGS = []

# í´ë¡œì§•: "êµ¬ê¸€ì— uni2road ê²€ìƒ‰í•´ë¼" (ì´ˆê°„ë‹¨ ë²„ì „)
CLOSINGS = []

# ==========================================
# [Query Agent] ê²Œì‹œê¸€ ë¶„ì„ ë° RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (gemini-2.5-flash-lite)
# ==========================================
QUERY_AGENT_PROMPT = """ë‹¹ì‹ ì€ ëŒ€í•™ ì…ì‹œ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ì„ ë¶„ì„í•˜ëŠ” **Query Agent**ì…ë‹ˆë‹¤.

## ì—­í• 
ê²Œì‹œê¸€ì„ ì½ê³  **ë„ì›€ì´ í•„ìš”í•œ ìˆ˜í—˜ìƒì˜ ì§ˆë¬¸**ì¸ì§€ íŒë‹¨í•œ í›„, í•„ìš”ì‹œ RAG ê²€ìƒ‰ì„ ìœ„í•œ í•¨ìˆ˜ í˜¸ì¶œì„ ìƒì„±í•˜ì„¸ìš”.
ë‹¹ì‹ ì˜ ì—­í• ì€ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ json í˜•ì‹ì˜ í•¨ìˆ˜ í˜¸ì¶œì…ë‹ˆë‹¤. ë‹¹ì‹ ì´ ì°¾ì€ ì •ë³´ì™€ ëŒ€í™”ì˜ ë§¥ë½ì„ ì¢…í•©í•˜ì—¬ main agentê°€ ìµœì¢…ì ì¸ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
ì•„ë˜ì— ëª…ì‹œëœ ì¶œë ¥ í˜•ì‹ì„ ì§€í‚¤ì„¸ìš”. ì •í™•í•œ í•¨ìˆ˜ë¥¼ ì˜¬ë°”ë¥´ê²Œ í˜¸ì¶œí•˜ì—¬ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.

## ğŸš¨ 1ì°¨ í•„í„° - PASS í•´ì•¼ í•˜ëŠ” ê²½ìš° (ë¹ˆ ë°°ì—´ ë°˜í™˜)
ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹ë˜ë©´ function_callsë¥¼ ë¹ˆ ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
1. **ì´ë¯¸ í•©ê²©í•œ ì‚¬ëŒ**: "í•©ê²© í›„ê¸°", "ìµœì´ˆí•©", "í•©ê²©í–ˆìŠµë‹ˆë‹¤", "ëŒ€í•™ ê°‘ë‹ˆë‹¤" ë“±
2. **ì •ë³´ ê³µìœ /ìë£Œ ë°°í¬**: ì§ˆë¬¸ì´ ì•„ë‹ˆë¼ íŒì„ ì•Œë ¤ì£¼ëŠ” ê¸€, ìë£Œ ë‚˜ëˆ”ê¸€
3. **ê´‘ê³ /í™ë³´**: í•™ì› í™ë³´, ê³¼ì™¸ ëª¨ì§‘, ìŠ¤í„°ë”” ëª¨ì§‘
4. **ê³µì§€ì‚¬í•­**: ì¹´í˜ ê³µì§€, í•„ë… ë“±
5. **ë‹¨ìˆœ ì¡ë‹´**: ì—°ì• , ìœ ë¨¸, ì…ì‹œì™€ ë¬´ê´€í•œ ì¼ìƒ
6. ê³µë¶€ë²•, í•™êµìƒí™œì— ê´€í•œ ì§ˆë¬¸
7. ì´ì™¸ ê¸°íƒ€ 'ì…ì‹œìš”ê°•, ì…ê²°, ëŒ€í•™ë³„ ì ìˆ˜ í™˜ì‚°&ë¹„êµ' ìë£Œë¥¼ í†µí•´ ëŒ€ë‹µí•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸.(ì˜ˆ, í•™ì› ì¶”ì²œ, ì»¤ë¦¬ ì¶”ì²œ, ê³µë¶€ë²• ìƒë‹´, ë©˜íƒˆ ìƒë‹´ ë“±)
8. ì‹œê°„ìƒ ìœ íš¨í•˜ì§€ ì•Šì€ ì§ˆë¬¸(ì˜ˆë¥¼ ë“¤ì–´, 2026 ì…ì‹œ í•©ê²© ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì§ˆë¬¸ì€ ì´ë¯¸ ê²°ê³¼ê°€ ë‚˜ì™”ìœ¼ë¯€ë¡œ ìœ íš¨í•˜ì§€ ì•ŠìŒ.)

## 'ì…ì‹œìš”ê°•, ì…ê²°, ëŒ€í•™ë³„ ì ìˆ˜ í™˜ì‚°&ë¹„êµ' ìë£Œë¥¼ í†µí•´ ëª…í™•í•˜ê²Œ ëŒ€ë‹µ ê°€ëŠ¥í•œ ì§ˆë¬¸ë§Œ ê¹Œë‹¤ë¡­ê²Œ ì„ ì •í•˜ì„¸ìš”. ê·¸ ì™¸ ì§ˆë¬¸ì€ ëª¨ë‘ ë¹ˆ ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.



## ì‹œì  ë™ê¸°í™”
- 2026ë…„ 1ì›” (2026í•™ë…„ë„ ì…ì‹œ ì¢…ë£Œ)
- "ì˜¬í•´" = 2026í•™ë…„ë„
- "ì‘ë…„ ì…ê²°" = 2025í•™ë…„ë„
- "ë‚˜ ê³ 1ì¸ë°" -> 2028ë…„ë„ ì…ì‹œ, "ë‚˜ 18ì‚´ì¸ë°" -> 2027ë…„ë„ ì…ì‹œ(ë‚˜ì´ì— ë§ëŠ” ì…ì‹œ ìš”ê°• ìš°ì„  íƒìƒ‰)
- ì…ì‹œ ê²°ê³¼ëŠ” ìµœì‹  ìë£Œë§Œ ì‚¬ìš©(2025í•™ë…„ë„)

## ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜

### univ(university, query)
íŠ¹ì • ëŒ€í•™ì˜ ì…ì‹œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
- university: ëŒ€í•™ ì •ì‹ëª…ì¹­ (ì„œìš¸ëŒ€í•™êµ, ê²½í¬ëŒ€í•™êµ)
- query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì—°ë„ + ì „í˜• + í•™ê³¼ ëª…ì‹œ)

ì˜ˆì‹œ:
- "ì„œìš¸ëŒ€ ê°€ëŠ” ë²•" -> univ("ì„œìš¸ëŒ€í•™êµ", "ì„œìš¸ëŒ€í•™êµ 2026í•™ë…„ë„ ëª¨ì§‘ìš”ê°•")
- "ì„œìš¸ëŒ€ ê¸°ê³„ê³¼ ì •ì‹œ" â†’ univ("ì„œìš¸ëŒ€í•™êµ", "2026í•™ë…„ë„ ê¸°ê³„ê³µí•™ë¶€ ì •ì‹œ")
- "ë‚˜ ê³ 1ì¸ë° ê²½í¬ëŒ€ ë†ì–´ì´Œ ì „í˜• ì•Œë ¤ì¤˜" â†’ univ("ê²½í¬ëŒ€í•™êµ", "2028 ê²½í¬ëŒ€í•™êµ ë†ì–´ì´Œ ì „í˜•")

### consult(scores, target_univ, target_major, target_range)
ëŒ€í•™ ì…ê²° ì¡°íšŒ, í•™ìƒ ì„±ì  ëŒ€í•™ë³„ í™˜ì‚°ì ìˆ˜ ë³€í™˜, í•©ê²© ê°€ëŠ¥ì„± í‰ê°€
í•™ìƒ ì„±ì ì„ ë¶„ì„í•˜ì—¬ í•©ê²© ê°€ëŠ¥ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. í™˜ì‚°ì ìˆ˜ ê³„ì‚° í¬í•¨.
#### ì£¼ì˜: ì„±ì  ì •ë³´ê°€ ì§ˆë¬¸ì— ìˆìœ¼ë©´ scores ë¡œ ì‚¬ìš©, ì§ˆë¬¸ì— ì—†ê³  historyì— ìˆìœ¼ë©´ ê·¸ ì •ë³´ë¥¼ scores ë¡œ ì‚¬ìš©, ë‘˜ ë‹¤ ì—†ìœ¼ë©´ consult í˜¸ì¶œ ì•ˆ í•¨
- scores: ì„±ì  ë”•ì…”ë„ˆë¦¬ {"êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1}, ...}
- target_univ: ë¶„ì„ ëŒ€ìƒ ëŒ€í•™ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ [])
- target_major: ê´€ì‹¬ í•™ê³¼ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ [])
- target_range: ë¶„ì„ ë²”ìœ„ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ [] = ì „ì²´ ë²”ìœ„)

#### ì„±ì  ì…ë ¥ í˜•ì‹
1. ì¶•ì•½í˜• (5ìë¦¬): "11232" â†’ êµ­ì–´/ìˆ˜í•™/ì˜ì–´/íƒêµ¬1/íƒêµ¬2 ë“±ê¸‰
2. ì¶•ì•½í˜• (6ìë¦¬): "211332" â†’ í•œêµ­ì‚¬/êµ­ì–´/ìˆ˜í•™/ì˜ì–´/íƒêµ¬1/íƒêµ¬2 ë“±ê¸‰
3. ë“±ê¸‰: "êµ­ì–´ 1ë“±ê¸‰", "ìˆ˜í•™ 2ë“±ê¸‰"
4. í‘œì¤€ì ìˆ˜: "ìˆ˜í•™ 140ì ", "ìˆ˜í•™ í‘œì¤€ì ìˆ˜ 140"
5. ë°±ë¶„ìœ„: "êµ­ì–´ ë°±ë¶„ìœ„ 98"

#### ê³¼ëª©ëª… ì²˜ë¦¬
- ì¼ë°˜ ê³¼ëª©ëª… (ì„ íƒê³¼ëª© ë¯¸ì–¸ê¸‰): êµ­ì–´, ìˆ˜í•™, ì˜ì–´, í•œêµ­ì‚¬, íƒêµ¬1, íƒêµ¬2 â†’ ê·¸ëŒ€ë¡œ ì¶œë ¥
- êµ¬ì²´ì  ì„ íƒê³¼ëª© (ëª…ì‹œëœ ê²½ìš°): í™”ë²•ê³¼ì‘ë¬¸(í™”ì‘), ì–¸ì–´ì™€ë§¤ì²´(ì–¸ë§¤), ë¯¸ì ë¶„, í™•ë¥ ê³¼í†µê³„(í™•í†µ), ê¸°í•˜, ìƒëª…ê³¼í•™1(ìƒ1), ì§€êµ¬ê³¼í•™1(ì§€1), ìƒí™œê³¼ìœ¤ë¦¬(ìƒìœ¤), ì‚¬íšŒë¬¸í™”(ì‚¬ë¬¸) ë“± â†’ ê³¼ëª©ëª… ê·¸ëŒ€ë¡œ ì¶œë ¥
- ì„±ì ì´ ì¶”ì • ê°€ëŠ¥í•œ ê²½ìš°ì—ëŠ” ì„ì˜ë¡œ ì¶”ì •í•˜ì—¬ ì¶œë ¥: "êµ­ì–´ ì˜ì–´ëŠ” 1ì¸ë° ìˆ˜í•™ì€ ì¢€ ëª»í•´ìš” -> 3ë“±ê¸‰ìœ¼ë¡œ ì¶”ì •"

#### ì„±ì  ì¶œë ¥ í˜•ì‹
```json
{
  "scores": {
    "êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1},
    "ìˆ˜í•™": {"type": "í‘œì¤€ì ìˆ˜", "value": 140},
    "ì˜ì–´": {"type": "ë“±ê¸‰", "value": 2},
    "í•œêµ­ì‚¬": {"type": "ë“±ê¸‰", "value": 1},
    "íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 1, "ê³¼ëª©ëª…": "ìƒí™œê³¼ìœ¤ë¦¬"},
    "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 2, "ê³¼ëª©ëª…": "ì‚¬íšŒë¬¸í™”"}
  }
}
```
- type: "ë“±ê¸‰", "í‘œì¤€ì ìˆ˜", "ë°±ë¶„ìœ„"
- íƒêµ¬ ê³¼ëª©ì€ í‚¤ë¥¼ "íƒêµ¬1", "íƒêµ¬2"ë¡œ ê³ ì •í•˜ê³ , ê³¼ëª©ëª…ì´ ì–¸ê¸‰ëœ ê²½ìš° "ê³¼ëª©ëª…" í•„ë“œ ì¶”ê°€
- í•œêµ­ì‚¬ëŠ” í•­ìƒ í¬í•¨ (ë¯¸ì–¸ê¸‰ ì‹œ 1ë“±ê¸‰ìœ¼ë¡œ ê¸°ë³¸ ì¶”ì •)

ì„±ì  ì˜ˆì‹œ:
- "11232" â†’ {"êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1}, "ìˆ˜í•™": {"type": "ë“±ê¸‰", "value": 1}, "ì˜ì–´": {"type": "ë“±ê¸‰", "value": 2}, "í•œêµ­ì‚¬": {"type": "ë“±ê¸‰", "value": 1}, "íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 3}, "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 2}}
- "êµ­ì–´ í™”ì‘ 1ë“±ê¸‰, ìˆ˜í•™ ë¯¸ì  140ì " â†’ {"êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1, "ì„ íƒê³¼ëª©": "í™”ë²•ê³¼ì‘ë¬¸"}, "ìˆ˜í•™": {"type": "í‘œì¤€ì ìˆ˜", "value": 140, "ì„ íƒê³¼ëª©": "ë¯¸ì ë¶„"}}
- "ìƒìœ¤ 2ë“±ê¸‰ ì‚¬ë¬¸ 1ë“±ê¸‰" â†’ {"íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 2, "ê³¼ëª©ëª…": "ìƒí™œê³¼ìœ¤ë¦¬"}, "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 1, "ê³¼ëª©ëª…": "ì‚¬íšŒë¬¸í™”"}}
- "ë¬¼1 ì§€1 1ë“±ê¸‰" â†’ {"íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 1, "ê³¼ëª©ëª…": "ë¬¼ë¦¬í•™1"}, "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 1, "ê³¼ëª©ëª…": "ì§€êµ¬ê³¼í•™1"}}

target_range ì˜µì…˜ (ìƒˆë¡œìš´ íŒì • ê¸°ì¤€):
- ["ì•ˆì •"]: ë‚´ ì ìˆ˜ >= ì•ˆì •ì»· (safeScore), í•©ê²© í™•ë¥  ë§¤ìš° ë†’ìŒ
- ["ì ì •"]: ë‚´ ì ìˆ˜ >= ì ì •ì»· (appropriateScore), í•©ê²© ê°€ëŠ¥ì„± ë†’ìŒ
- ["ì†Œì‹ "]: ë‚´ ì ìˆ˜ >= ì†Œì‹ ì»· (expectedScore), í•©ê²© ê°€ëŠ¥ì„± ìˆìŒ
- ["ë„ì „"]: ë‚´ ì ìˆ˜ >= ë„ì „ì»· (challengeScore), ë„ì „ì ì¸ ì§€ì›
- ["ì–´ë ¤ì›€"]: ë‚´ ì ìˆ˜ < ë„ì „ì»·, í•©ê²© ì–´ë ¤ì›€
- []: ë¹ˆ ë°°ì—´ = ëª¨ë“  ë²”ìœ„ (ê¸°ë³¸ê°’), scoreê°€ ì£¼ì–´ì§€ì§€ ì•Šìœ¼ë©´ í•­ìƒ ë¹ˆ ë°°ì—´
- í•™ìƒì´ ìê¸° ì„±ì ë§Œ ì…ë ¥í•œ ê²½ìš° -> [ì•ˆì •, ì ì •, ì†Œì‹ ]
ì˜ˆì‹œ:
- "ë‚˜ 11232ì¸ë° ê²½í¬ëŒ€ ê°ˆ ìˆ˜ ìˆì–´?" â†’ consult(scores, ["ê²½í¬ëŒ€í•™êµ"], [], [])
- "11112ë¡œ ê¸°ê³„ê³µí•™ ì–´ë”” ê°ˆê¹Œ?" â†’ consult(scores, [], ["ê¸°ê³„ê³µí•™"], [ì•ˆì •, ì ì •, ì†Œì‹ ])
- 'ë‚´ ì„±ì  ì–¸ë§¤ 99, ë¯¸ì  100, ì˜ì–´ 1ë“±ê¸‰, ë¬¼1 85, í™”2 93ì´ì•¼: -> consult(scores, [], [], [ì•ˆì •, ì ì •, ì†Œì‹ ])
- "ì ì • ëŒ€í•™ ì¶”ì²œí•´ì¤˜" â†’ consult(scores, [], [], ["ì ì •"])
- "ë„ì „ìœ¼ë¡œ ì„œìš¸ëŒ€ ì—°ì„¸ëŒ€ ê°€ëŠ¥í•´?" â†’ consult(scores, ["ì„œìš¸ëŒ€í•™êµ", "ì—°ì„¸ëŒ€í•™êµ"], [], ["ë„ì „"])

## ì¶œë ¥ í˜•ì‹
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì ˆëŒ€ ê¸ˆì§€.

### ë‹¨ì¼ í•¨ìˆ˜ í˜¸ì¶œ ì˜ˆì‹œ (ì˜¬í•´ ìˆ˜ëŠ¥ìœ¼ë¡œ ì„œìš¸ëŒ€ ê°€ë ¤ë©´ ì–´ë–»ê²Œ í•´?)
```json
{
  "function_calls": [
    {
      "function": "univ",
      "params": {
        "university": "ì„œìš¸ëŒ€í•™êµ",
        "query": "2026í•™ë…„ë„ ì„œìš¸ëŒ€í•™êµ ì •ì‹œ ëª¨ì§‘ìš”ê°•", "2025í•™ë…„ë„ ì„œìš¸ëŒ€í•™êµ ì •ì‹œ ì…ê²°"
      }
    }
  ]
}
```

### ì„±ì  ë¶„ì„ ì˜ˆì‹œ (ë‚˜ 11232ì¸ë° ê²½í¬ëŒ€ ê°ˆ ìˆ˜ ìˆì–´?)
```json
{
  "function_calls": [
    {
      "function": "consult",
      "params": {
        "scores": {
          "êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1},
          "ìˆ˜í•™": {"type": "ë“±ê¸‰", "value": 1},
          "ì˜ì–´": {"type": "ë“±ê¸‰", "value": 2},
          "íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 3},
          "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 2}
        },
        "target_univ": ["ê²½í¬ëŒ€í•™êµ"],
        "target_major": [],
        "target_range": []
      }
    },
    {
      "function": "univ",
      "params": {
        "university": "ê²½í¬ëŒ€í•™êµ",
        "query": "2026í•™ë…„ë„ ê²½í¬ëŒ€í•™êµ ì •ì‹œ ëª¨ì§‘ìš”ê°•"
      }
    }
  ]
}
```

### ì ì • ëŒ€í•™ ì¶”ì²œ ì˜ˆì‹œ (11112ì¸ë° ì ì • ëŒ€í•™ ì¶”ì²œí•´ì¤˜)
```json
{
  "function_calls": [
    {
      "function": "consult",
      "params": {
        "scores": {
          "êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1},
          "ìˆ˜í•™": {"type": "ë“±ê¸‰", "value": 1},
          "ì˜ì–´": {"type": "ë“±ê¸‰", "value": 1},
          "íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 1},
          "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 2}
        },
        "target_univ": [],
        "target_major": [],
        "target_range": ["ì ì •"]
      }
    }
  ]
}
```

## íŒë‹¨ ê·œì¹™
1. **ëŒ€í•™ëª… ì •ê·œí™”**: ì„œìš¸ëŒ€ â†’ ì„œìš¸ëŒ€í•™êµ, ê³ ëŒ€ â†’ ê³ ë ¤ëŒ€í•™êµ
2. **ì—°ë„ ëª…ì‹œ**: í•­ìƒ "XXXXí•™ë…„ë„" í¬í•¨
3. **ì„±ì  ì§ˆë¬¸**: ì„±ì  + íŠ¹ì • ëŒ€í•™ ì–¸ê¸‰ ì‹œ consult + univ ë™ì‹œ í˜¸ì¶œ
4. **ëŒ€í•™ëª… ì–¸ê¸‰ ì—†ëŠ” ë§‰ì—°í•œ ì§ˆë¬¸ì—ëŠ” consult í˜¸ì¶œ**:  
    - "ë‚´ ì„±ì (ì–¸ê¸‰)ìœ¼ë¡œ ì–´ë”” ê°ˆ ìˆ˜ ìˆì–´?" â†’ consult(scores, [], [], [ì•ˆì •, ì ì •, ì†Œì‹ ])
    - "ë©”ë””ì»¬ ê°€ë ¤ë©´ ê³µë¶€ ì–¼ë§ˆë‚˜ í•´ì•¼ í•´?" â†’ consult(scores, [], ['ì˜ì˜ˆê³¼', 'ì¹˜ì˜ˆê³¼', 'í•œì˜ì˜ˆê³¼', 'ìˆ˜ì˜ì˜ˆê³¼', 'ì•½í•™ê³¼'], [])
5. **ë¹„êµ ì§ˆë¬¸**: ì—¬ëŸ¬ ëŒ€í•™ ë¹„êµ ì‹œ ê°ê° univ í˜¸ì¶œ
6. **ê¸°ë³¸ê°’ì€ ë¹ˆ ë°°ì—´**: target_univ, target_major, target_range ëª¨ë‘ ëª…ì‹œ ì•ˆë˜ë©´ []
7. **ì •í™•í•œ ì˜ë„ íŒŒì•…**: 
    - "ê·¸ë˜ë„ ì–´ë””ê¹Œì§„ í™•ì‹¤íˆ ë ê¹Œ?" -> consult(scores, [], [], ["ì ì •", "ì•ˆì •"]), 
    - "ì–´ë””ê¹Œì§€ ê°ˆ ìˆ˜ ìˆì„ê¹Œ?" -> consult(scores, [], [], ["ë„ì „", "ì†Œì‹ "])
8. ì• ë§¤í•˜ë©´ í¬ê´„ì ìœ¼ë¡œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°(ì–´ì§œí”¼ main agentì—ì„œ ì •ë³´ ì„ ë³„, ë‹¨ ìµœëŒ€ í˜¸ì¶œ ìˆ˜ 3ê°œë¡œ ì œí•œ)
    - "ìˆ˜ë„ê¶Œ ê³µëŒ€ ì¤‘ì— 2ë“±ê¸‰ì´ ê°ˆ ê³³ ì•Œë ¤ì¤˜" -> consult(scores, [], [ê³µí•™], ["ì ì •", "ì•ˆì •"]) (ìˆ˜ë„ê¶Œì€ ë³€ìˆ˜ ì„¤ì •ì´ ì•ˆ ë˜ì§€ë§Œ, ëª¨ë“  ê³µëŒ€ì— ëŒ€í•´ì„œ ì¡°ì‚¬í•˜ë©´ main agentê°€ ì„ ë³„), 
    - "SKY ì¤‘ì— ê³µëŒ€ 1000ëª… ë„˜ê²Œ ë½‘ëŠ” ê³³ ì•Œë ¤ì¤˜ -> ì„œìš¸ëŒ€, ì—°ì„¸ëŒ€, ê³ ë ¤ëŒ€ ì „ë¶€ í˜¸ì¶œ

"""

# Query Agent ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ê´€ë¦¬ í˜ì´ì§€ì—ì„œ ìˆ˜ì • ê°€ëŠ¥)
DEFAULT_QUERY_PROMPT = QUERY_AGENT_PROMPT.strip()

# Answer Agent ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ê´€ë¦¬ í˜ì´ì§€ì—ì„œ ìˆ˜ì • ê°€ëŠ¥)
DEFAULT_ANSWER_PROMPT = """
[ì‘ì„± ì „ëµ: ì² ì €í•œ ë°ì´í„° ê¸°ë°˜ì˜ ì»¨ì„¤íŒ…]

0. **ìµœìš°ì„  ê·œì¹™**
    - í•™ìƒì˜ ì§ˆë¬¸ ë§¥ë½ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•´ì„œ ëŒ€ë‹µí•˜ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì •ë³´ ì¸ìš©, ë§¥ë½ìƒ ì–´ìƒ‰í•œ ë‹µë³€ì€ ì ˆëŒ€ë¡œ í•˜ì§€ ë§ˆì„¸ìš”.
    - í•™ìƒì˜ ì ìˆ˜(ì›ì ìˆ˜, ë°±ë¶„ìœ„, ë“±ê¸‰ ë“±)ì€ ë³¸ë¬¸ì— ìˆëŠ” ì ìˆ˜ë§Œ ì¸ìš©í•˜ì„¸ìš”, [ğŸ“š ê´€ë ¨ ì…ì‹œ ì •ë³´ (RAG)]ì—ì„œ í™˜ì‚°ëœ ë°±ë¶„ìœ„ëŠ” ì ˆëŒ€ ì¸ìš©í•˜ì§€ ë§ˆì„¸ìš”, ëŒ€í•™ë³„ í™˜ì‚° ì ìˆ˜ë§Œ ì¸ìš©í•´ë„ ë©ë‹ˆë‹¤.

1. **ğŸ¯ í•µì‹¬ ê°€ì¹˜ (Value Proposition)**
   - **ë¬´ì¡°ê±´ 'ìˆ«ì'ë¡œ ëŒ€ë‹µ:** RAGë¡œ ê°€ì ¸ì˜¨ **'ì‘ë…„ ì…ê²°(70% ì»·)', 'í™˜ì‚° ì ìˆ˜', 'ëª¨ì§‘ ì¸ì› ë³€í™”'** ë“± êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ ë°˜ë“œì‹œ í•˜ë‚˜ ì´ìƒ ì¸ìš©í•´.
   - **ì •ì‹œ/êµê³¼ íŒŒì´í„° ëª¨ë“œ:** ì§ˆë¬¸ìì˜ ì„±ì ì´ ì• ë§¤í•˜ë©´ "ì´ ì ìˆ˜ë©´ OOëŒ€ëŠ” ìœ„í—˜í•˜ê³  â–³â–³ëŒ€ê°€ ì°¨ë¼ë¦¬ ë‚«ë‹¤"ëŠ” ì‹ìœ¼ë¡œ **ëŒ€ì•ˆì„ ì œì‹œ**í•˜ê±°ë‚˜ **í•©ê²© ê°€ëŠ¥ì„±ì„ ëƒ‰ì •í•˜ê²Œ ì§„ë‹¨**í•´.
   - **ë‚´ìš©:** "ìœ ë¦¬í•˜ë‹¤" ê°™ì€ ëª¨í˜¸í•œ í‘œí˜„ ëŒ€ì‹ , "ì‘ë…„ ì»·(392ì )ë³´ë‹¤ 3ì  ë†’ì•„ ì•ˆì •ì ì´ì—ìš”", "í•´ë‹¹ ëŒ€í•™ì—ì„œ ê°€ì¥ ë‚®ì€ ì»·(ì‹¬ë¦¬í•™ê³¼, 395ì )ë³´ë‹¤ 2ì  ë‚®ì•„ ì–´ë ¤ì›Œìš”."ì²˜ëŸ¼ **ìˆ˜ì¹˜ ì¤‘ì‹¬**ìœ¼ë¡œ ì„¤ëª….

2. **ğŸ—£ï¸ í†¤ì•¤ë§¤ë„ˆ (Tone & Manner)**
   - **ë§íˆ¬:** "~í•´ìš”"ì²´ ì‚¬ìš©í•˜ë˜, ìì‹ ê° ìˆê³  í™•ì‹ ì— ì°¬ ì–´ì¡°. (ì¹œì ˆí•œ ì„ ë°° ë§íˆ¬, ë¬´ë¡€í•˜ì§€ ì•Šê²Œ.)
   - **ê¸¸ì´:** 3~4ë¬¸ì¥. (ì„œë¡  ë¹¼ê³  ë³¸ë¡ ë§Œ ë”±.)

3. **ì¶œë ¥ í˜•ì‹:** ëŒ“ê¸€ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
   - **ë‹¤ë¥¸ ë§ ì—†ì´ ëŒ“ê¸€ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”**
   - **ë§ˆí¬ë‹¤ìš´ í˜•ì‹(**, ##, > ë“±) ì‚¬ìš© ê¸ˆì§€.** í‰ë¬¸(Plain Text)ë§Œ ì‚¬ìš©.
   - **ì¤‘ìš”** ìœ„ [ğŸ“š ê´€ë ¨ ì…ì‹œ ì •ë³´ (RAG)] ë¸”ë¡ì— ì íŒ ìˆ˜ì¹˜(ì…ê²°, ì»·, í™˜ì‚°ì ìˆ˜, ëª¨ì§‘ì¸ì› ë“±)ë¥¼ ê·¼ê±°ë¡œ í•œ ë‹µë³€ì´ ì•„ë‹ ê²½ìš°ì—ëŠ” ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”, ìë£Œì— ê·¼ê±°í•˜ì§€ ì•Šê³  ìì²´ ìƒì„±í•˜ëŠ” ëŒ“ê¸€ì€ ì ˆëŒ€ë¡œ ë‹¬ì§€ ë§ˆì„¸ìš”.
   - **ì¤‘ìš”** ìƒì„±í•œ ëŒ“ê¸€ì´ ëª…í™•í•˜ê²Œ ë„ì›€ë˜ì§€ ì•Šê±°ë‚˜, í•™ìƒì´ ê³µê²©ì ìœ¼ë¡œ ëŠë‚„ ìˆ˜ ìˆë‹¤ê³  ëŠê»´ì§€ë©´ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”.
"""

def generate_function_calls(title, content, existing_comments=""):
    """
    Query Agentë¡œ ê²Œì‹œê¸€ ë¶„ì„ ë° í•¨ìˆ˜ í˜¸ì¶œ ìƒì„±
    
    Args:
        title: ê²Œì‹œê¸€ ì œëª©
        content: ê²Œì‹œê¸€ ë³¸ë¬¸
        existing_comments: ê¸°ì¡´ ëŒ“ê¸€ ëª©ë¡ (ì¤‘ë³µ ì²´í¬ìš©)
    
    Returns:
        list: function_calls ë°°ì—´ (PASSì¸ ê²½ìš° ë¹ˆ ë°°ì—´)
        None: ì—ëŸ¬ ë°œìƒ ì‹œ
    """
    try:
        query_instruction = load_query_prompt()
        
        # ë¶€ì ì ˆí•œ ê¸€ ì˜ˆì‹œ ë¡œë“œ (ì·¨ì†Œë¨ ì¤‘ 'ë¶€ì ì ˆí•œ ê¸€' ì‚¬ìœ )
        inappropriate_posts = get_query_agent_examples(max_examples=20)
        inappropriate_section = format_query_agent_examples(inappropriate_posts)
        
        # ê¸°ì¡´ ëŒ“ê¸€ ì„¹ì…˜ (ì¤‘ë³µ ë°©ì§€ ì²´í¬)
        existing_comments_section = ""
        if existing_comments:
            existing_comments_section = f"""
[âš ï¸ ê¸°ì¡´ ëŒ“ê¸€ - ì¤‘ë³µ ë°©ì§€ ì²´í¬]
ì•„ë˜ëŠ” ì´ ê²Œì‹œê¸€ì— ì´ë¯¸ ë‹¬ë¦° ëŒ“ê¸€ë“¤ì…ë‹ˆë‹¤.
ë§Œì•½ "uni2road", "ì…ì‹œ ai", "ìˆ˜í—˜ìƒ ai", "êµ¬ê¸€ì— uni2road" ë“± ìš°ë¦¬ ë´‡ì´ ë‹¨ ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ëŒ“ê¸€ì´ ìˆë‹¤ë©´,
ë°˜ë“œì‹œ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”. ì¤‘ë³µ ëŒ“ê¸€ì€ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤.
íŠ¹íˆ "í•˜ëŠ˜ë‹´ì•„", "ë„êµ°" ë‹‰ë„¤ì„ì˜ ëŒ“ê¸€ì´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ë¹ˆ ë°°ì—´ ë°˜í™˜!

{existing_comments[:300]}
"""
        
        prompt = f"""{query_instruction}
{inappropriate_section}
{existing_comments_section}

[ê²Œì‹œê¸€]
ì œëª©: {title}
ë³¸ë¬¸: {content[:1000]}

ìœ„ ê²Œì‹œê¸€ì„ ë¶„ì„í•˜ì—¬ function_callsë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.
âš ï¸ ì¤‘ìš”: ê¸°ì¡´ ëŒ“ê¸€ì— ì´ë¯¸ ìš°ë¦¬ ë´‡ì˜ ëŒ“ê¸€ì´ ìˆë‹¤ë©´ ë¹ˆ ë°°ì—´ {{"function_calls": []}}ì„ ë°˜í™˜í•˜ì„¸ìš”.
"""
        
        # ìƒˆë¡œìš´ í†µí•© AI í˜¸ì¶œ í•¨ìˆ˜ ì‚¬ìš©
        result_text = call_ai_model(prompt, is_json_response=True, temperature=1.0, max_tokens=2048)
        
        if not result_text:
            print(f"  -> [Query Agent] AI ì‘ë‹µ ì—†ìŒ")
            return None
        
        # JSON íŒŒì‹±
        result = json.loads(result_text)
        function_calls = result.get("function_calls", [])
        
        if not function_calls:
            print(f"  -> [Query Agent] PASS (ë„ì›€ ë¶ˆí•„ìš” ë˜ëŠ” ì´ë¯¸ ëŒ“ê¸€ ìˆìŒ)")
            return []
        
        print(f"  -> [Query Agent] {len(function_calls)}ê°œ í•¨ìˆ˜ í˜¸ì¶œ ìƒì„±")
        for call in function_calls:
            print(f"     - {call.get('function')}: {call.get('params', {}).get('university', '')} {call.get('params', {}).get('query', '')[:50]}")
        
        return function_calls
        
    except json.JSONDecodeError as e:
        print(f"  -> [Query Agent] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"     ì›ë³¸: {result_text[:200] if result_text else 'None'}")
        return None
    except Exception as e:
        print(f"  -> [Query Agent] ì—ëŸ¬: {e}")
        return None


# ==========================================
# [RAG] Backend API í˜¸ì¶œë¡œ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
# ==========================================
def get_rag_context_from_functions(function_calls):
    """
    function_callsë¥¼ Backend APIë¡œ ì „ì†¡í•˜ì—¬ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        function_calls: Query Agentê°€ ìƒì„±í•œ function_calls ë°°ì—´
        
    Returns:
        dict: RAG ê²€ìƒ‰ ê²°ê³¼ (chunks, document_titles ë“±)
        None: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
    """
    if not function_calls:
        return None
        
    try:
        # Backend API í˜¸ì¶œ
        response = requests.post(
            f"{BACKEND_URL}/api/functions/execute",
            json={"function_calls": function_calls},
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if result.get("success"):
                print(f"  -> [RAG API] ì‘ë‹µ ì„±ê³µ")
                return result.get("results", {})
        
        print(f"  -> [RAG API] ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        return None
        
    except requests.exceptions.ConnectionError:
        print(f"  -> [RAG API] ì—°ê²° ì‹¤íŒ¨ - Backend ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš” ({BACKEND_URL})")
        return None
    except requests.exceptions.Timeout:
        print("  -> [RAG API] íƒ€ì„ì•„ì›ƒ")
        return None
    except Exception as e:
        print(f"  -> [RAG API ì—ëŸ¬] {e}")
        return None


def format_rag_context(rag_results):
    """
    RAG ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    """
    if not rag_results:
        print("  -> [RAG] rag_resultsê°€ ë¹„ì–´ìˆìŒ")
        return "[ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ]"
    
    context_parts = []
    total_chunks = 0
    
    print(f"  -> [RAG DEBUG] rag_results keys: {list(rag_results.keys())}")
    
    for key, result in rag_results.items():
        chunks = result.get("chunks", [])
        total_chunks += len(chunks)
        print(f"  -> [RAG DEBUG] {key}: {len(chunks)}ê°œ ì²­í¬")
        
        if not chunks:
            # ê²€ìƒ‰í–ˆì§€ë§Œ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°ë„ í‘œì‹œ
            context_parts.append(f"\n=== {result.get('university', 'ì „ì²´')} ===\n[ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ]")
            continue
        
        # ì²« ë²ˆì§¸ ì²­í¬ êµ¬ì¡° í™•ì¸
        if chunks:
            first_chunk = chunks[0]
            print(f"  -> [RAG DEBUG] ì²« ì²­í¬ keys: {list(first_chunk.keys())}")
            print(f"  -> [RAG DEBUG] ì²« ì²­í¬ content ê¸¸ì´: {len(first_chunk.get('content', ''))}")
        
        context_parts.append(f"\n=== ê´€ë ¨ ì…ì‹œ ì •ë³´ ({result.get('university', 'ì „ì²´')}) ===")
        
        for i, chunk in enumerate(chunks[:10], 1):  # ìƒìœ„ 10ê°œ ì²­í¬ ì‚¬ìš©
            content = chunk.get("content", "")  # ì „ì²´ ë‚´ìš© ì „ë‹¬ (ì œí•œ ì œê±°)
            context_parts.append(f"[{i}] {content}")
    
    if not context_parts:
        return "[ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ]"
    
    final_context = "\n".join(context_parts)
    print(f"  -> [RAG DEBUG] ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(final_context)}ì")
    return final_context


# ==========================================
# [í•µì‹¬] ê²Œì‹œê¸€ ë¶„ì„ ë° ë‹µë³€ ìƒì„±
# ==========================================
def analyze_and_generate_reply(title, content, use_rag=True, existing_comments=""):
    """ê²Œì‹œê¸€ ë¶„ì„ ë° ë‹µë³€ ìƒì„±
    
    Args:
        title: ê²Œì‹œê¸€ ì œëª©
        content: ê²Œì‹œê¸€ ë³¸ë¬¸
        use_rag: RAG ì‚¬ìš© ì—¬ë¶€
        existing_comments: ê¸°ì¡´ ëŒ“ê¸€ ëª©ë¡ (AI ë”ë¸”ì²´í¬ìš©)
    """
    try:
        # Query Agentë¡œ ê²Œì‹œê¸€ ë¶„ì„ ë° function_calls ìƒì„±
        print("  -> [Query Agent] ê²Œì‹œê¸€ ë¶„ì„ ì¤‘...")
        function_calls = generate_function_calls(title, content, existing_comments=existing_comments)
        
        if function_calls is None:
            # ì—ëŸ¬ ë°œìƒ
            print("  -> [Query Agent] ì—ëŸ¬ - ê¸°ë³¸ PASS ì²˜ë¦¬")
            return None
        
        if not function_calls:
            # PASS (ë„ì›€ ë¶ˆí•„ìš”í•œ ê²Œì‹œê¸€)
            return None
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        rag_context = ""
        if use_rag:
            print("  -> [RAG] Backend API í˜¸ì¶œ ì¤‘...")
            rag_results = get_rag_context_from_functions(function_calls)
            if rag_results:
                rag_context = format_rag_context(rag_results)
                print(f"  -> [RAG] ì»¨í…ìŠ¤íŠ¸ {len(rag_context)}ì ë¡œë“œ ì™„ë£Œ")
            else:
                print("  -> [RAG] ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰)")
        
        # RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        rag_section = ""
        if rag_context:
            rag_section = f"""[ğŸ“š ê´€ë ¨ ì…ì‹œ ì •ë³´ (RAG)]
ì•„ë˜ëŠ” ê²Œì‹œê¸€ê³¼ ê´€ë ¨ëœ ê³µì‹ ì…ì‹œ ì •ë³´ì…ë‹ˆë‹¤. ë‹µë³€ ì‹œ ì°¸ê³ í•˜ì„¸ìš”.
{rag_context}
"""
        
        instruction = load_answer_prompt()
        
        # ==========================================
        # í•™ìŠµ ë°ì´í„° ë¡œë“œ (comment_history.jsonì—ì„œ ì‹¤ì‹œê°„)
        # - ì¢‹ì€ ì˜ˆì‹œ: ê²Œì‹œì™„ë£Œ/ìŠ¹ì¸ë¨ ì¤‘ 10ê°œ
        # - ë‚˜ìœ ì˜ˆì‹œ: ì·¨ì†Œë¨ ì¤‘ 10ê°œ
        # ==========================================
        good_examples, bad_examples = get_answer_agent_examples(max_good=10, max_bad=10)
        examples_section = format_answer_agent_examples(good_examples, bad_examples)
        
        instruction = load_answer_prompt()
        
        # ê¸°ì¡´ ëŒ“ê¸€ ì„¹ì…˜ (AI ë”ë¸”ì²´í¬ìš©)
        existing_comments_section = ""
        if existing_comments:
            existing_comments_section = f"""
[âš ï¸ ê¸°ì¡´ ëŒ“ê¸€ ëª©ë¡ - ì¤‘ë³µ ë°©ì§€ ì²´í¬]
ì•„ë˜ëŠ” ì´ ê²Œì‹œê¸€ì— ì´ë¯¸ ë‹¬ë¦° ëŒ“ê¸€ë“¤ì…ë‹ˆë‹¤.
ë§Œì•½ ì•„ë˜ ëŒ“ê¸€ ì¤‘ "uni2road", "ì…ì‹œ ai", "ìˆ˜í—˜ìƒ ai" ë“± ìš°ë¦¬ ë´‡ì´ ë‹¨ ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ëŒ“ê¸€ì´ ìˆê±°ë‚˜,
"í•˜ëŠ˜ë‹´ì•„", "ë„êµ°" ë‹‰ë„¤ì„ì˜ ëŒ“ê¸€ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ë¹ˆ ë¬¸ìì—´ì„ ë°˜í™˜í•˜ì„¸ìš”. 
ì¤‘ë³µ ëŒ“ê¸€ì€ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤.

{existing_comments[:500]}
"""
        
        # í”„ë¡¬í”„íŠ¸ ìˆœì„œ: 1.ì‚¬ìš©ìì •ì˜ â†’ 2.í•™ìŠµì˜ˆì‹œ â†’ 3.ê²Œì‹œê¸€ â†’ 4.RAG
        prompt = f"""[âœï¸ ì‘ì„± ì§€ì¹¨ ë° ì—­í• ]
{instruction}

{examples_section}

[ğŸ“‹ ê²Œì‹œê¸€ ì •ë³´]
ì œëª©: {title}
ë³¸ë¬¸: {content[:1000]}
{existing_comments_section}
{rag_section}

âš ï¸ ì¤‘ìš”: ê¸°ì¡´ ëŒ“ê¸€ì— ì´ë¯¸ ìš°ë¦¬ ë´‡(uni2road, ì…ì‹œ ai, í•˜ëŠ˜ë‹´ì•„, ë„êµ°)ì˜ ëŒ“ê¸€ì´ ìˆë‹¤ë©´ ë¹ˆ ë¬¸ìì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
"""
        print(f"  -> [Answer Agent] í•™ìŠµ ë°ì´í„° ë¡œë“œ (ì¢‹ì€ ì˜ˆì‹œ {len(good_examples)}ê°œ, ë‚˜ìœ ì˜ˆì‹œ {len(bad_examples)}ê°œ)")
        
        # ìƒˆë¡œìš´ í†µí•© AI í˜¸ì¶œ í•¨ìˆ˜ ì‚¬ìš©
        result = call_ai_model(prompt, is_json_response=False, temperature=1.0, max_tokens=2048)
        
        if not result:
            print(f"  -> [Answer Agent] AI ì‘ë‹µ ì—†ìŒ - PASS")
            return None
        
        result = result.replace('"', '').replace("'", "")  # ë”°ì˜´í‘œ ì œê±°
        result = result.strip()
        
        # í•  ë§ ì—†ê±°ë‚˜ 20ì ì´í•˜ë©´ ëŒ“ê¸€ ì•ˆ ë‹¬ê³  ë„˜ì–´ê° (ë¹ˆ ë°°ì—´/ì§§ì€ ë¬´ì˜ë¯¸ ì‘ë‹µ ì°¨ë‹¨)
        if not result or len(result) <= 20:
            print(f"  -> [Answer Agent] í•  ë§ ì—†ìŒ/ì§§ìŒ ({len(result)}ì) - PASS (ëŒ“ê¸€ ìƒëµ)")
            return None
        
        # ëœë¤ ì˜¤í”„ë‹/í´ë¡œì§• ì„ íƒ (ë¹„ì–´ìˆìœ¼ë©´ ì‚¬ìš© ì•ˆí•¨)
        opening = random.choice(OPENINGS) if OPENINGS else ""
        closing = random.choice(CLOSINGS) if CLOSINGS else ""
        
        # ê³ ì • í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        if opening and closing:
            formatted_reply = f"""{opening}

{result}

{closing}"""
        elif opening:
            formatted_reply = f"""{opening}

{result}"""
        elif closing:
            formatted_reply = f"""{result}

{closing}"""
        else:
            formatted_reply = result 
        
        # ê´€ë¦¬ í˜ì´ì§€ 5ì—´(ì›ê¸€/ì¿¼ë¦¬/í•¨ìˆ˜ê²°ê³¼/ìµœì¢…ë‹µë³€/ë§í¬) ì €ì¥ìš©
        # í•¨ìˆ˜ê²°ê³¼ = RAG ì»¨í…ìŠ¤íŠ¸ë§Œ (í•¨ìˆ˜ ì¶œë ¥ê°’)
        extra = {
            "post_content": (title or "") + "\n\n" + (content or "")[:2000],
            "query": json.dumps(function_calls, ensure_ascii=False),
            "function_result": rag_context or ""
        }
        return (formatted_reply, extra)
            
    except Exception as e:
        print(f"  -> [AI ì—ëŸ¬] {e}")
        return None

# ==========================================
# [ê¸°ë³¸ í•¨ìˆ˜]
# ==========================================
def load_history():
    if not os.path.exists(HISTORY_FILE): return set()
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return set(line.strip() for line in f.readlines())
    except: return set()

def append_history(link):
    """ë°©ë¬¸ ê¸°ë¡ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€) - ê°€ì‹¤í–‰ ëª¨ë“œëŠ” ê¸°ë¡ ì•ˆ í•¨
    
    âš ï¸ ì¤‘ìš”: ì´ í•¨ìˆ˜ëŠ” ê¸€ ë¶„ì„ ì „ì— í˜¸ì¶œë˜ì–´ì•¼ Race Conditionì„ ë°©ì§€í•  ìˆ˜ ìˆìŒ
    """
    # ê°€ì‹¤í–‰ ëª¨ë“œëŠ” visited_historyì— ê¸°ë¡í•˜ì§€ ì•ŠìŒ
    if DRY_RUN:
        return
    
    try:
        import fcntl  # íŒŒì¼ ë½ìš©
        
        # article ID ì¶”ì¶œí•˜ì—¬ ì •ê·œí™”ëœ í˜•íƒœë¡œ ì €ì¥
        article_id = extract_article_id(link)
        
        # íŒŒì¼ ë½ì„ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ì“°ê¸° ë°©ì§€
        with open(HISTORY_FILE, "a+", encoding="utf-8") as f:
            try:
                fcntl.flock(f.fileno(), fcntl.LOCK_EX)  # ë°°íƒ€ì  ë½ íšë“
                
                # íŒŒì¼ ì²˜ìŒìœ¼ë¡œ ì´ë™í•˜ì—¬ ê¸°ì¡´ ë‚´ìš© í™•ì¸
                f.seek(0)
                existing_ids = set()
                for line in f:
                    stored_url = line.strip()
                    if stored_url:
                        stored_id = extract_article_id(stored_url) or stored_url
                        existing_ids.add(stored_id)
                
                # ì¤‘ë³µ ì²´í¬ (article ID ê¸°ì¤€)
                check_id = article_id if article_id else link
                if check_id in existing_ids:
                    return  # ì´ë¯¸ ìˆìœ¼ë©´ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                
                # íŒŒì¼ ëìœ¼ë¡œ ì´ë™í•˜ì—¬ ì¶”ê°€
                f.seek(0, 2)  # SEEK_END
                f.write(link + "\n")
                f.flush()
                
            finally:
                fcntl.flock(f.fileno(), fcntl.LOCK_UN)  # ë½ í•´ì œ
                
    except ImportError:
        # fcntlì´ ì—†ëŠ” í™˜ê²½ (Windows ë“±)ì—ì„œëŠ” ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        try:
            existing = load_history()
            if link in existing:
                return
            with open(HISTORY_FILE, "a", encoding="utf-8") as f:
                f.write(link + "\n")
        except:
            pass
    except Exception as e:
        print(f"  -> [ê²½ê³ ] íˆìŠ¤í† ë¦¬ ê¸°ë¡ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ì¤‘ë³µ ëŒ“ê¸€ë³´ë‹¤ëŠ” ë‚˜ìŒ)


def extract_article_id(url):
    """URLì—ì„œ article ID ì¶”ì¶œ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
    
    ì§€ì› í˜•ì‹:
    - https://cafe.naver.com/f-e/cafes/10197921/articles/29429119
    - https://cafe.naver.com/suhui/29429119
    - https://cafe.naver.com/suhui/29429119?art=...
    """
    import re
    # ìˆ«ìë§Œ ì¶”ì¶œ (ë§ˆì§€ë§‰ ìˆ«ì ê·¸ë£¹ì´ article ID)
    # f-e í˜•ì‹: /articles/29429119
    match = re.search(r'/articles/(\d+)', url)
    if match:
        return match.group(1)
    
    # ì¼ë°˜ í˜•ì‹: /ì¹´í˜ëª…/29429119 ë˜ëŠ” /ì¹´í˜ëª…/29429119?...
    match = re.search(r'/([a-zA-Z0-9_]+)/(\d+)(?:\?|$)', url)
    if match:
        return match.group(2)
    
    return None


def check_post_date(driver, min_year=2026, min_month=2):
    """ê²Œì‹œê¸€ ì‘ì„± ë‚ ì§œê°€ ìµœì†Œ ë‚ ì§œ ì´í›„ì¸ì§€ í™•ì¸
    
    Args:
        driver: Selenium WebDriver
        min_year: ìµœì†Œ ì—°ë„ (ê¸°ë³¸ê°’: 2026)
        min_month: ìµœì†Œ ì›” (ê¸°ë³¸ê°’: 2)
        
    Returns:
        bool: ìµœì†Œ ë‚ ì§œ ì´í›„ë©´ True, ì´ì „ì´ë©´ False
    """
    try:
        # ë„¤ì´ë²„ ì¹´í˜ ê²Œì‹œê¸€ ë‚ ì§œ ì…€ë ‰í„°ë“¤
        date_selectors = [
            "span.date",  # ì¼ë°˜ì ì¸ ë‚ ì§œ í‘œì‹œ
            "span.article_info span",  # ê²Œì‹œê¸€ ì •ë³´ ë‚´ ë‚ ì§œ
            "div.article_info span.date",
            "span.WriterInfo__date--mYIJg",  # ìƒˆ UI
            "div.ArticleWriterInfo span.date",
            "span.se_publishDate",
        ]
        
        date_text = None
        for selector in date_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for elem in elements:
                    text = elem.text.strip()
                    # ë‚ ì§œ í˜•ì‹ í™•ì¸ (YYYY.MM.DD ë˜ëŠ” YY.MM.DD ë˜ëŠ” MM.DD ë“±)
                    if text and ('.' in text or '-' in text or '/' in text):
                        date_text = text
                        break
                if date_text:
                    break
            except:
                continue
        
        if not date_text:
            # ë‚ ì§œë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ì¼ë‹¨ ì²˜ë¦¬ (ì•ˆì „í•˜ê²Œ)
            print("  -> [ë‚ ì§œ] ë‚ ì§œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (ì²˜ë¦¬ ì§„í–‰)")
            return True
        
        # ë‚ ì§œ íŒŒì‹±
        import re
        
        # "2026.02.08" ë˜ëŠ” "26.02.08" ë˜ëŠ” "2026-02-08" í˜•ì‹
        match = re.search(r'(\d{2,4})[.\-/](\d{1,2})[.\-/](\d{1,2})', date_text)
        if match:
            year = int(match.group(1))
            month = int(match.group(2))
            
            # 2ìë¦¬ ì—°ë„ ì²˜ë¦¬
            if year < 100:
                year += 2000
            
            # ìµœì†Œ ë‚ ì§œ ì´í›„ì¸ì§€ í™•ì¸
            if year > min_year:
                return True
            elif year == min_year and month >= min_month:
                return True
            else:
                print(f"  -> [PASS] ì˜¤ë˜ëœ ê¸€ì…ë‹ˆë‹¤. ({year}.{month:02d})")
                return False
        
        # "2ì›” 8ì¼" ë˜ëŠ” "02.08" í˜•ì‹ (ì˜¬í•´ë¡œ ê°€ì •)
        match = re.search(r'(\d{1,2})[ì›”.\-/]\s*(\d{1,2})', date_text)
        if match:
            month = int(match.group(1))
            # í˜„ì¬ ì—°ë„ë¡œ ê°€ì •
            current_year = datetime.now().year
            if current_year >= min_year and month >= min_month:
                return True
            elif current_year > min_year:
                return True
            else:
                print(f"  -> [PASS] ì˜¤ë˜ëœ ê¸€ì…ë‹ˆë‹¤. ({current_year}.{month:02d})")
                return False
        
        # íŒŒì‹± ì‹¤íŒ¨ì‹œ ì¼ë‹¨ ì²˜ë¦¬
        print(f"  -> [ë‚ ì§œ] ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_text} (ì²˜ë¦¬ ì§„í–‰)")
        return True
        
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒì‹œ ì¼ë‹¨ ì²˜ë¦¬
        print(f"  -> [ë‚ ì§œ] ë‚ ì§œ í™•ì¸ ì˜¤ë¥˜: {e} (ì²˜ë¦¬ ì§„í–‰)")
        return True


def check_my_comment_exists(driver, my_nicknames=None):
    """ê²Œì‹œê¸€ í˜ì´ì§€ì—ì„œ ë‚´ ëŒ“ê¸€ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
    
    Args:
        driver: Selenium WebDriver
        my_nicknames: ë‚´ ë‹‰ë„¤ì„ ëª©ë¡ (ì—†ìœ¼ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        
    Returns:
        bool: ë‚´ ëŒ“ê¸€ì´ ìˆìœ¼ë©´ True
    """
    # ë‹‰ë„¤ì„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    if my_nicknames is None:
        # configì—ì„œ ë‹‰ë„¤ì„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (MY_NICKNAMES ìš°ì„ , ì—†ìœ¼ë©´ MY_NICKNAME)
        my_nicknames = getattr(config, 'MY_NICKNAMES', None)
        if not my_nicknames:
            single_nickname = getattr(config, 'MY_NICKNAME', None)
            if single_nickname:
                my_nicknames = [single_nickname]
            else:
                # ë‹‰ë„¤ì„ì´ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° NAVER_ID ì‚¬ìš©
                my_nicknames = [getattr(config, 'NAVER_ID', '')]
    
    # ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(my_nicknames, str):
        my_nicknames = [my_nicknames]
    
    if not my_nicknames or not any(my_nicknames):
        return False
    
    try:
        # ëŒ“ê¸€ ì˜ì—­ì—ì„œ ë‹‰ë„¤ì„ ì°¾ê¸°
        comment_authors = driver.find_elements(By.CSS_SELECTOR, "span.comment_nickname, a.comment_nickname, span.nick, a.nick")
        
        for author in comment_authors:
            author_text = author.text.strip()
            for nickname in my_nicknames:
                if nickname and (nickname in author_text or author_text in nickname):
                    print(f"  -> [Skip] ì´ë¯¸ ë‚´ ëŒ“ê¸€ì´ ìˆìŒ (ë‹‰ë„¤ì„: {author_text})")
                    return True
        
        # ì¶”ê°€: ëŒ“ê¸€ ì‘ì„±ì ë§í¬ì—ì„œ ID í™•ì¸
        comment_author_links = driver.find_elements(By.CSS_SELECTOR, "a[href*='memberid=']")
        for link in comment_author_links:
            href = link.get_attribute('href') or ''
            if f"memberid={config.NAVER_ID}" in href:
                print(f"  -> [Skip] ì´ë¯¸ ë‚´ ëŒ“ê¸€ì´ ìˆìŒ (ID: {config.NAVER_ID})")
                return True
                
    except Exception as e:
        print(f"  -> [ê²½ê³ ] ëŒ“ê¸€ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return False


def is_already_commented(link):
    """visited_history.txt, comment_history.json, skip_links.jsonì—ì„œ ì´ë¯¸ ì²˜ë¦¬í•œ ê¸€ì¸ì§€ í™•ì¸"""
    # ê°€ì‹¤í–‰ ëª¨ë“œì—ì„œëŠ” ì¤‘ë³µ ì²´í¬ ì•ˆ í•¨
    if DRY_RUN:
        return False
    
    # ì…ë ¥ ë§í¬ì—ì„œ article ID ì¶”ì¶œ
    input_article_id = extract_article_id(link)
    if not input_article_id:
        # ID ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¹„êµ
        input_article_id = link
    
    # 0. visited_history.txt ì²´í¬ (ê°€ì¥ ë¨¼ì €! - ì´ íŒŒì¼ì´ ê°€ì¥ ë¹ ë¥´ê²Œ ê¸°ë¡ë¨)
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                for line in f:
                    stored_url = line.strip()
                    if not stored_url:
                        continue
                    stored_article_id = extract_article_id(stored_url) or stored_url
                    if stored_article_id == input_article_id:
                        print(f"  -> [Skip] visited_history.txtì— ì´ë¯¸ ìˆìŒ")
                        return True
        except:
            pass
    
    # 1. comment_history.json ì²´í¬
    if os.path.exists(COMMENT_HISTORY_FILE):
        try:
            with open(COMMENT_HISTORY_FILE, "r", encoding="utf-8") as f:
                history = json.load(f)
                for item in history:
                    stored_url = item.get("post_url", "")
                    stored_article_id = extract_article_id(stored_url) or stored_url
                    
                    # article IDë¡œ ë¹„êµ (statusì™€ ê´€ê³„ì—†ì´ ì²˜ë¦¬ëœ ì  ìˆìœ¼ë©´ ìŠ¤í‚µ)
                    # pending, approved, posted, cancelled ëª¨ë‘ ì¤‘ë³µìœ¼ë¡œ ì²˜ë¦¬
                    if stored_article_id == input_article_id:
                        status = item.get("status", "unknown")
                        print(f"  -> [Skip] comment_history.jsonì— ì´ë¯¸ ìˆìŒ (status: {status})")
                        return True
        except:
            pass
    
    # 2. skip_links.json ì²´í¬ (ìˆ˜ë™ ìŠ¤í‚µ ë§í¬)
    if os.path.exists(SKIP_LINKS_FILE):
        try:
            with open(SKIP_LINKS_FILE, "r", encoding="utf-8") as f:
                skip_links = json.load(f)
                for item in skip_links:
                    if item.get("article_id") == input_article_id:
                        print(f"  -> [Skip] ìˆ˜ë™ ìŠ¤í‚µ ë§í¬ì…ë‹ˆë‹¤.")
                        return True
        except:
            pass
    
    return False

# ==========================================
# [í¬ë¡¤ëŸ¬ ë´‡] - ë°˜ìë™ ì‹œìŠ¤í…œ: ëŒ“ê¸€ ìƒì„±ë§Œ í•˜ê³  pending ìƒíƒœë¡œ ì €ì¥
# ==========================================
def run_search_bot():
    """í¬ë¡¤ëŸ¬ ë´‡: ê²Œì‹œê¸€ì„ ë¹ ë¥´ê²Œ íƒìƒ‰í•˜ê³  ëŒ“ê¸€ì„ ìƒì„±í•˜ì—¬ pending ìƒíƒœë¡œ ì €ì¥"""
    global should_stop
    
    # ì„¤ì • ë¡œë“œ
    bot_config = load_bot_config()
    rest_minutes = bot_config.get("rest_minutes", 3)
    print(f"[í¬ë¡¤ëŸ¬] ë°˜ìë™ ëª¨ë“œ - ëŒ“ê¸€ ìƒì„±ë§Œ í•˜ê³  ì‹¤ì œ ê²Œì‹œí•˜ì§€ ì•ŠìŒ")
    
    chrome_options = Options()
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)
    
    # ì„œë²„ìš© Headless ì˜µì…˜
    if HEADLESS_MODE:
        print("[ë´‡] Headless ëª¨ë“œë¡œ ì‹¤í–‰")
        
        # PID ê¸°ë°˜ ê³ ìœ  user-data-dir ìƒì„± (Chrome crash ë°©ì§€)
        user_data_dir = os.path.join(SCRIPT_DIR, f"chrome_data_{os.getpid()}")
        os.makedirs(user_data_dir, exist_ok=True)
        print(f"[ë´‡] Chrome user-data-dir: {user_data_dir}")
        
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--disable-software-rasterizer")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-setuid-sandbox")
        chrome_options.add_argument(f"--user-data-dir={user_data_dir}")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--disable-features=VizDisplayCompositor")
        chrome_options.add_argument("--disable-background-networking")
        chrome_options.add_argument("--disable-default-apps")
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    else:
        chrome_options.add_argument("--start-maximized")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    wait = WebDriverWait(driver, 10) 

    try:
        print("========== [ìë™ ëŒ“ê¸€ ë´‡ (ì„œë²„ìš©)] ==========")
        visited_links = load_history()
        
        # ì¿ í‚¤ ê¸°ë°˜ ë¡œê·¸ì¸
        if not load_cookies(driver):
            print("[ë´‡] ë¡œê·¸ì¸ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        print("[í¬ë¡¤ëŸ¬] ë´‡ ì‹œì‘! (ì¢…ë£Œ: Ctrl+C ë˜ëŠ” .stop_bot íŒŒì¼ ìƒì„±)")
        print("=" * 60)
        print("[ë°˜ìë™ ëª¨ë“œ] ëŒ“ê¸€ì„ ìƒì„±í•˜ì—¬ ëŒ€ê¸°ì—´ì— ì €ì¥í•©ë‹ˆë‹¤")
        print("=" * 60)

        while not should_stop:
            # ì¢…ë£Œ í”Œë˜ê·¸ í™•ì¸
            if check_stop_flag():
                print("[ë´‡] ì •ì§€ í”Œë˜ê·¸ ê°ì§€, ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # ì„¤ì • ë¦¬ë¡œë“œ (ëŸ°íƒ€ì„ ë³€ê²½ ë°˜ì˜)
            bot_config = load_bot_config()
            rest_minutes = bot_config.get("rest_minutes", 3)
            
            # ê²€ìƒ‰í•  ê²Œì‹œíŒ(ë©”ë‰´) ID: ì—†ìœ¼ë©´ ì „ì²´(0)
            menu_ids = getattr(config, "CAFE_MENU_IDS", None) or [0]
            if not menu_ids:
                menu_ids = [0]
            
            # í‚¤ì›Œë“œ ë¡œë“œ (ë§¤ ì‚¬ì´í´ë§ˆë‹¤ ìƒˆë¡œ ë¡œë“œí•˜ì—¬ ì‹¤ì‹œê°„ ë°˜ì˜)
            keywords = load_keywords()
            banned_keywords = load_banned_keywords()
            print(f"[INFO] ê²€ìƒ‰ í‚¤ì›Œë“œ {len(keywords)}ê°œ, ê¸ˆì§€ í‚¤ì›Œë“œ {len(banned_keywords)}ê°œ ë¡œë“œë¨")
            
            # ë©€í‹° ì¹´í˜ ì„¤ì • ë¡œë“œ (ì—†ìœ¼ë©´ í˜„ì¬ ì¹´í˜ë§Œ)
            multi_cafes = getattr(config, "MULTI_CAFES", None)
            if not multi_cafes:
                multi_cafes = [{"club_id": config.CLUB_ID, "cafe_name": config.CAFE_NAME, "name": "í˜„ì¬ì¹´í˜"}]
            
            print(f"[INFO] í¬ë¡¤ë§ ëŒ€ìƒ ì¹´í˜: {[c['name'] for c in multi_cafes]}")
            
            # ê° ì¹´í˜ë³„ë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰
            for cafe_info in multi_cafes:
                if should_stop or check_stop_flag():
                    break
                
                current_club_id = cafe_info["club_id"]
                current_cafe_name = cafe_info["cafe_name"]
                cafe_display_name = cafe_info.get("name", current_cafe_name)
                
                print(f"\n{'='*50}")
                print(f"[ì¹´í˜] {cafe_display_name} (club_id: {current_club_id})")
                print(f"{'='*50}")
                
                # ì „ì²´ê¸€ë³´ê¸°ì—ì„œë§Œ ê²€ìƒ‰ (menu_id=0)
                for keyword in keywords:
                    if should_stop or check_stop_flag():
                        break
                        
                    try:
                        encoded = urllib.parse.quote(keyword)
                        search_url = f"https://cafe.naver.com/f-e/cafes/{current_club_id}/menus/0?viewType=L&ta=ARTICLE_COMMENT&page=1&q={encoded}"
                        
                        print(f"\n>>> [{cafe_display_name}] í‚¤ì›Œë“œ: '{keyword}'")
                        driver.get(search_url)
                        time.sleep(random.uniform(1, 2))  # ë¹ ë¥¸ í¬ë¡¤ë§
                        
                        all_links = driver.find_elements(By.XPATH, "//a[contains(@href, '/articles/') and not(contains(@class, 'comment'))]")
                        
                        if not all_links: continue

                        target_links = []
                        for a_tag in all_links[:50]:  # 50ê°œ ê¸€ íƒìƒ‰
                            try:
                                raw_link = a_tag.get_attribute('href')
                                clean_link = raw_link.split('?')[0] if '?' in raw_link else raw_link
                                title = a_tag.text.strip()
                                if len(title) > 1: 
                                    target_links.append((clean_link, title))
                            except: continue
                        
                        print(f" -> ëŒ€ìƒ(ì¤‘ë³µí¬í•¨): {len(target_links)}ê°œ")

                        for link, title in target_links:
                            if should_stop or check_stop_flag():
                                break
                                
                            if link in visited_links:
                                print(f" -> [Skip] ë°©ê¸ˆ ì²˜ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. ({title[:10]}...)")
                                continue
                            
                            # ì¶”ê°€ ì¤‘ë³µ ì²´í¬: visited_history.txt, comment_history.json, skip_links.json ëª¨ë‘ í™•ì¸
                            if is_already_commented(link):
                                print(f" -> [Skip] ì´ë¯¸ ì²˜ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. ({title[:10]}...)")
                                visited_links.add(link)
                                continue
                            
                            # âš ï¸ ì¤‘ìš”: ë¶„ì„ ì „ì— ë¨¼ì € ê¸°ë¡í•˜ì—¬ Race Condition ë°©ì§€
                            # ë‹¤ë¥¸ í‚¤ì›Œë“œ ê²€ìƒ‰ì—ì„œ ê°™ì€ ê¸€ì´ ë™ì‹œì— ì²˜ë¦¬ë˜ëŠ” ê²ƒì„ ë°©ì§€
                            append_history(link)
                            visited_links.add(link)
                            
                            try:
                                print(f"\n[ë¶„ì„] {title[:15]}...")
                                driver.get(link)
                                time.sleep(random.uniform(1, 2))  # ë¹ ë¥¸ í¬ë¡¤ë§
                                
                                try: driver.switch_to.frame("cafe_main")
                                except: pass

                                # âš ï¸ ì¤‘ìš”: ë‚´ ëŒ“ê¸€ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ (í¬ë¡¤ë§ ë‹¨ê³„ ì²´í¬)
                                if check_my_comment_exists(driver):
                                    print("  -> [PASS] ì´ë¯¸ ë‚´ ëŒ“ê¸€ì´ ìˆëŠ” ê¸€ì…ë‹ˆë‹¤.")
                                    driver.switch_to.default_content()
                                    continue
                                
                                # âš ï¸ ë‚ ì§œ ì²´í¬: 2026ë…„ 2ì›” ì´í›„ ê¸€ë§Œ ì²˜ë¦¬
                                if not check_post_date(driver, min_year=2026, min_month=2):
                                    driver.switch_to.default_content()
                                    continue

                                content = ""
                                try: content = driver.find_element(By.CSS_SELECTOR, "div.se-main-container").text
                                except:
                                    try: content = driver.find_element(By.CSS_SELECTOR, "div.ContentRenderer").text
                                    except: content = ""
                                
                                # ê¸ˆì§€ í‚¤ì›Œë“œ ì²´í¬
                                if contains_banned_keyword(title, content, banned_keywords):
                                    print(f"  -> [PASS] ê¸ˆì§€ í‚¤ì›Œë“œ í¬í•¨ ê¸€ì…ë‹ˆë‹¤.")
                                    driver.switch_to.default_content()
                                    continue
                                
                                # ëŒ“ê¸€ ëª©ë¡ë„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ AIê°€ ë”ë¸”ì²´í¬í•  ìˆ˜ ìˆë„ë¡ í•¨
                                existing_comments = ""
                                try:
                                    comment_elements = driver.find_elements(By.CSS_SELECTOR, "span.text_comment, div.comment_text")
                                    if comment_elements:
                                        existing_comments = "\n".join([c.text.strip()[:100] for c in comment_elements[:10]])
                                except:
                                    pass
                                
                                result = analyze_and_generate_reply(title, content, existing_comments=existing_comments)
                                
                                if result is None:
                                    print("  -> [PASS] (í•©ê²©ì/ê´‘ê³ /ë¬´ê´€í•¨/ì´ë¯¸ ëŒ“ê¸€ ìˆìŒ)")
                                    # ì´ë¯¸ ìœ„ì—ì„œ ê¸°ë¡í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê¸°ë¡í•˜ì§€ ì•ŠìŒ
                                    driver.switch_to.default_content()
                                    continue
                                
                                ai_reply, extra = result
                                print(f"  -> [ì‘ì„±] {ai_reply[:50]}...")

                                try:
                                    # ë°˜ìë™ ëª¨ë“œ: ëŒ“ê¸€ì„ ì‹¤ì œë¡œ ë‹¬ì§€ ì•Šê³  pending ìƒíƒœë¡œ ì €ì¥
                                    print("  -> [ëŒ€ê¸°ì—´ ì¶”ê°€] ëŒ“ê¸€ ìƒì„± ì™„ë£Œ (ìŠ¹ì¸ ëŒ€ê¸°)")
                                    print(f"     ìƒì„±ëœ ëŒ“ê¸€: {ai_reply[:100]}...")
                                    # íˆìŠ¤í† ë¦¬ì— pending ìƒíƒœë¡œ ì €ì¥ (visited_historyëŠ” ì´ë¯¸ ìœ„ì—ì„œ ê¸°ë¡ë¨)
                                    save_comment_history(link, title, ai_reply, success=True, status="pending", **extra)

                                except Exception as e:
                                    print(f"  -> [ì‹¤íŒ¨] {e}")
                                    save_comment_history(link, title, ai_reply, success=False, status="pending", **extra)

                                driver.switch_to.default_content()

                            except Exception as e:
                                print(f"  -> [ì—ëŸ¬] {e}")
                                driver.switch_to.default_content()
                                time.sleep(2)

                    except Exception as e:
                        err_msg = str(e)
                        print(f"  -> [í‚¤ì›Œë“œ ì—ëŸ¬] {err_msg[:100]}")
                        # Chrome í¬ë˜ì‹œ ê°ì§€ ì‹œ ì¬ì‹œì‘
                        if "Connection refused" in err_msg or "invalid session" in err_msg.lower():
                            print("[ê²½ê³ ] Chrome í¬ë˜ì‹œ ê°ì§€! ë¸Œë¼ìš°ì € ì¬ì‹œì‘...")
                            try:
                                driver.quit()
                            except:
                                pass
                            # ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘
                            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
                            wait = WebDriverWait(driver, 10)
                            if not load_cookies(driver):
                                print("[ì—ëŸ¬] ì¬ë¡œê·¸ì¸ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                                return
                            print("[ë³µêµ¬] ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì™„ë£Œ!")
            
            if should_stop:
                break
            
            # í¬ë¡¤ëŸ¬ ëª¨ë“œ: ì§§ì€ íœ´ì‹ í›„ ë‹¤ìŒ ì‚¬ì´í´
            print(f">>> íœ´ì‹ {rest_minutes}ë¶„...")
            for _ in range(rest_minutes * 6):  # 10ì´ˆ ë‹¨ìœ„ë¡œ ì²´í¬
                if should_stop or check_stop_flag():
                    break
                time.sleep(10)

    except KeyboardInterrupt:
        print("\n[í¬ë¡¤ëŸ¬] ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\n[í¬ë¡¤ëŸ¬] ì˜ˆì™¸ ë°œìƒ: {e}")
    finally:
        print("[í¬ë¡¤ëŸ¬] ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
        driver.quit()
        
        # Headless ëª¨ë“œì—ì„œ user-data-dir ì •ë¦¬
        if HEADLESS_MODE:
            user_data_dir = os.path.join(SCRIPT_DIR, f"chrome_data_{os.getpid()}")
            if os.path.exists(user_data_dir):
                try:
                    import shutil
                    shutil.rmtree(user_data_dir)
                    print(f"[í¬ë¡¤ëŸ¬] Chrome user-data-dir ì •ë¦¬ ì™„ë£Œ: {user_data_dir}")
                except Exception as e:
                    print(f"[í¬ë¡¤ëŸ¬] Chrome user-data-dir ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        print("[í¬ë¡¤ëŸ¬] ì¢…ë£Œ ì™„ë£Œ")


# ==========================================
# [ê²Œì‹œ ì›Œì»¤] - ìŠ¹ì¸ëœ ëŒ“ê¸€ë§Œ ë”œë ˆì´ ì ìš©í•˜ì—¬ ì‹¤ì œ ê²Œì‹œ
# ==========================================
POSTER_STOP_FLAG_FILE = os.path.join(SCRIPT_DIR, ".stop_poster")
poster_should_stop = False

def check_poster_stop_flag():
    """ê²Œì‹œ ì›Œì»¤ ì •ì§€ í”Œë˜ê·¸ íŒŒì¼ í™•ì¸"""
    if os.path.exists(POSTER_STOP_FLAG_FILE):
        os.remove(POSTER_STOP_FLAG_FILE)
        return True
    return False

def load_approved_comments():
    """ìŠ¹ì¸ëœ ëŒ“ê¸€ ëª©ë¡ ë¡œë“œ"""
    if not os.path.exists(COMMENT_HISTORY_FILE):
        return []
    try:
        with open(COMMENT_HISTORY_FILE, "r", encoding="utf-8") as f:
            history = json.load(f)
            return [c for c in history if c.get("status") == "approved"]
    except:
        return []

def update_comment_status(comment_id, new_status, posted_at=None, is_duplicate=False):
    """ëŒ“ê¸€ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    if not os.path.exists(COMMENT_HISTORY_FILE):
        return False
    try:
        with open(COMMENT_HISTORY_FILE, "r", encoding="utf-8") as f:
            history = json.load(f)
        
        for comment in history:
            if comment.get("id") == comment_id:
                comment["status"] = new_status
                if posted_at:
                    comment["posted_at"] = posted_at
                if is_duplicate:
                    comment["is_duplicate"] = True
                # action_historyì— ì¶”ê°€
                if "action_history" not in comment:
                    comment["action_history"] = []
                comment["action_history"].append({
                    "action": new_status,
                    "timestamp": datetime.now().isoformat()
                })
                break
        
        with open(COMMENT_HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"[ê²Œì‹œì›Œì»¤] ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def run_poster_bot_with_restart():
    """ê²Œì‹œ ì›Œì»¤ ìë™ ì¬ì‹œì‘ ë˜í¼"""
    max_restart_count = 0  # ë¬´ì œí•œ ì¬ì‹œì‘
    restart_count = 0
    
    while True:
        try:
            print(f"\n[ê²Œì‹œì›Œì»¤] ì‹œì‘... (ì¬ì‹œì‘ íšŸìˆ˜: {restart_count})")
            run_poster_bot_once()
            print("[ê²Œì‹œì›Œì»¤] ì •ìƒ ì¢…ë£Œ")
            break  # ì •ìƒ ì¢…ë£Œì‹œ ë£¨í”„ íƒˆì¶œ
        except KeyboardInterrupt:
            print("\n[ê²Œì‹œì›Œì»¤] ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
            break
        except Exception as e:
            restart_count += 1
            print(f"\n[ê²Œì‹œì›Œì»¤] ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(f"[ê²Œì‹œì›Œì»¤] 10ì´ˆ í›„ ìë™ ì¬ì‹œì‘... ({restart_count}ë²ˆì§¸)")
            
            if max_restart_count > 0 and restart_count >= max_restart_count:
                print(f"[ê²Œì‹œì›Œì»¤] ìµœëŒ€ ì¬ì‹œì‘ íšŸìˆ˜({max_restart_count})ì— ë„ë‹¬. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            time.sleep(10)  # 10ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œì‘
            continue

def run_poster_bot_once():
    """ê²Œì‹œ ì›Œì»¤: ìŠ¹ì¸ëœ ëŒ“ê¸€ë§Œ ë”œë ˆì´ ì ìš©í•˜ì—¬ ì‹¤ì œ ê²Œì‹œ (ë‹¨ì¼ ì‹¤í–‰)"""
    global poster_should_stop
    poster_should_stop = False
    
    # ì„¤ì • ë¡œë“œ
    bot_config = load_bot_config()
    min_delay_sec = bot_config.get("min_delay_seconds", 50)
    cph_min = bot_config.get("comments_per_hour_min", 5)
    cph_max = bot_config.get("comments_per_hour_max", 10)
    
    print(f"[ê²Œì‹œì›Œì»¤] ì‹œì‘ - ì‹œê°„ë‹¹ {cph_min}~{cph_max}ê°œ ëŒ“ê¸€ ê²Œì‹œ")
    
    chrome_options = Options()
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)
    
    if HEADLESS_MODE:
        print("[ê²Œì‹œì›Œì»¤] Headless ëª¨ë“œë¡œ ì‹¤í–‰")
        user_data_dir = os.path.join(SCRIPT_DIR, f"chrome_poster_{os.getpid()}")
        os.makedirs(user_data_dir, exist_ok=True)
        
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument(f"--user-data-dir={user_data_dir}")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
    else:
        chrome_options.add_argument("--start-maximized")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    wait = WebDriverWait(driver, 10)
    
    try:
        # ì¿ í‚¤ ê¸°ë°˜ ë¡œê·¸ì¸
        if not load_cookies(driver):
            print("[ê²Œì‹œì›Œì»¤] ë¡œê·¸ì¸ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        print("[ê²Œì‹œì›Œì»¤] ë¡œê·¸ì¸ ì„±ê³µ! ìŠ¹ì¸ëœ ëŒ“ê¸€ ê²Œì‹œ ì‹œì‘...")
        
        while not poster_should_stop:
            if check_poster_stop_flag():
                print("[ê²Œì‹œì›Œì»¤] ì •ì§€ í”Œë˜ê·¸ ê°ì§€, ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # ìŠ¹ì¸ëœ ëŒ“ê¸€ ë¡œë“œ
            approved_comments = load_approved_comments()
            
            if not approved_comments:
                print("[ê²Œì‹œì›Œì»¤] ìŠ¹ì¸ëœ ëŒ“ê¸€ ì—†ìŒ. 30ì´ˆ í›„ ì¬í™•ì¸...")
                for _ in range(6):  # 5ì´ˆ ë‹¨ìœ„ë¡œ ì²´í¬
                    if poster_should_stop or check_poster_stop_flag():
                        break
                    time.sleep(5)
                continue
            
            print(f"[ê²Œì‹œì›Œì»¤] ìŠ¹ì¸ëœ ëŒ“ê¸€ {len(approved_comments)}ê°œ ë°œê²¬")
            
            for comment in approved_comments:
                if poster_should_stop or check_poster_stop_flag():
                    break
                
                comment_id = comment.get("id")
                post_url = comment.get("post_url")
                ai_reply = comment.get("comment")
                title = comment.get("post_title", "")[:20]
                
                print(f"\n[ê²Œì‹œ] {title}... -> {post_url[:50]}...")
                
                try:
                    # URL í˜•ì‹ ë³€í™˜: /f-e/cafes/... í˜•ì‹ì„ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    import re
                    converted_url = post_url
                    fe_match = re.search(r'/f-e/cafes/\d+/articles/(\d+)', post_url)
                    if fe_match:
                        article_id = fe_match.group(1)
                        # configì—ì„œ ì¹´í˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                        converted_url = f"https://cafe.naver.com/{config.CAFE_NAME}/{article_id}"
                        print(f"  -> URL ë³€í™˜: {converted_url}")
                    
                    driver.get(converted_url)
                    time.sleep(3)
                    
                    # iframe ì „í™˜
                    try:
                        driver.switch_to.frame("cafe_main")
                    except:
                        pass
                    
                    # âš ï¸ ìµœì¢… ì¤‘ë³µ ì²´í¬: ì‹¤ì œ ê²Œì‹œ ì§ì „ì— ë‚´ ëŒ“ê¸€ì´ ìˆëŠ”ì§€ í™•ì¸
                    if check_my_comment_exists(driver):
                        print(f"  -> [Skip] ì´ë¯¸ ë‚´ ëŒ“ê¸€ì´ ìˆìŒ - ê²Œì‹œì™„ë£Œ(ì¤‘ë³µ)ë¡œ ì²˜ë¦¬")
                        update_comment_status(comment_id, "posted", posted_at=datetime.now().isoformat(), is_duplicate=True)
                        driver.switch_to.default_content()
                        continue
                    
                    # ëŒ“ê¸€ ì…ë ¥ (ì´ì „ ì‘ë™ ì½”ë“œì™€ ë™ì¼)
                    inbox = wait.until(EC.presence_of_element_located((By.CLASS_NAME, "comment_inbox")))
                    driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", inbox)
                    inbox.click()
                    time.sleep(1)
                    
                    try:
                        driver.find_element(By.CLASS_NAME, "comment_inbox_text").send_keys(ai_reply)
                    except:
                        driver.switch_to.active_element.send_keys(ai_reply)
                    
                    time.sleep(1)
                    driver.find_element(By.XPATH, "//*[text()='ë“±ë¡']").click()
                    
                    # Alert ì²˜ë¦¬
                    try:
                        WebDriverWait(driver, 2).until(EC.alert_is_present())
                        driver.switch_to.alert.accept()
                        print(f"  -> [ì‹¤íŒ¨] Alert ë°œìƒ")
                        update_comment_status(comment_id, "failed")
                        driver.switch_to.default_content()
                        continue
                    except:
                        pass
                    
                    print(f"  -> [ê²Œì‹œ ì™„ë£Œ]")
                    update_comment_status(comment_id, "posted", posted_at=datetime.now().isoformat())
                    
                    driver.switch_to.default_content()
                    
                    # ë”œë ˆì´ ì ìš©
                    bot_config = load_bot_config()
                    min_delay_sec = bot_config.get("min_delay_seconds", 50)
                    cph_min = bot_config.get("comments_per_hour_min", 5)
                    cph_max = bot_config.get("comments_per_hour_max", 10)
                    
                    if cph_min and cph_max and 0 < cph_min <= cph_max:
                        d_max = 3600 / cph_min
                        d_min_cand = 3600 / cph_max
                        d_min = max(min_delay_sec, d_min_cand)
                        d_min = min(d_min, d_max - 1) if d_min >= d_max else d_min
                        d_max = max(d_max, d_min + 1)
                    else:
                        d_min, d_max = min_delay_sec, 720
                    
                    delay = random.uniform(d_min, d_max)
                    print(f"  -> ë‹¤ìŒ ëŒ“ê¸€ê¹Œì§€ {delay:.0f}ì´ˆ ëŒ€ê¸°...")
                    
                    # ëŒ€ê¸° ì¤‘ì—ë„ ì¢…ë£Œ í”Œë˜ê·¸ í™•ì¸
                    for _ in range(int(delay / 5)):
                        if poster_should_stop or check_poster_stop_flag():
                            break
                        time.sleep(5)
                    
                except Exception as e:
                    print(f"  -> [ì—ëŸ¬] {type(e).__name__}: {str(e)[:200]}")
                    import traceback
                    traceback.print_exc()
                    update_comment_status(comment_id, "failed")
                    driver.switch_to.default_content()
                    time.sleep(2)
    
    except KeyboardInterrupt:
        print("\n[ê²Œì‹œì›Œì»¤] ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\n[ê²Œì‹œì›Œì»¤] ì˜ˆì™¸ ë°œìƒ: {e}")
    finally:
        print("[ê²Œì‹œì›Œì»¤] ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
        driver.quit()
        
        if HEADLESS_MODE:
            user_data_dir = os.path.join(SCRIPT_DIR, f"chrome_poster_{os.getpid()}")
            if os.path.exists(user_data_dir):
                try:
                    import shutil
                    shutil.rmtree(user_data_dir)
                except:
                    pass
        
        print("[ê²Œì‹œì›Œì»¤] ì¢…ë£Œ ì™„ë£Œ")

def run_poster_bot():
    """ê²Œì‹œ ì›Œì»¤ - ë¬´í•œ ë£¨í”„ë¡œ ê³„ì† ì‹¤í–‰ (ì •ìƒ ì¢…ë£Œ ì‹œì—ë„ ì¬ì‹œì‘)"""
    restart_count = 0
    
    while True:
        try:
            print(f"\n{'='*60}")
            print(f"[ê²Œì‹œì›Œì»¤] ì‹œì‘... (ì¬ì‹œì‘ íšŸìˆ˜: {restart_count})")
            print(f"{'='*60}")
            run_poster_bot_once()
            # ì •ìƒ ì¢…ë£Œ ì‹œì—ë„ ì¬ì‹œì‘ (break ì œê±°)
            print("[ê²Œì‹œì›Œì»¤] ì‚¬ì´í´ ì™„ë£Œ, 10ì´ˆ í›„ ì¬ì‹œì‘...")
            time.sleep(10)
            restart_count += 1
        except KeyboardInterrupt:
            print("\n[ê²Œì‹œì›Œì»¤] ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
            break
        except Exception as e:
            restart_count += 1
            print(f"\n{'='*60}")
            print(f"[ê²Œì‹œì›Œì»¤] ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {str(e)[:200]}")
            print(f"[ê²Œì‹œì›Œì»¤] 10ì´ˆ í›„ ìë™ ì¬ì‹œì‘... ({restart_count}ë²ˆì§¸)")
            print(f"{'='*60}")
            time.sleep(10)
            continue

if __name__ == "__main__":
    # ë´‡ ì‹œì‘
    print("[ì´ˆê¸°í™”] í•™ìŠµ ë°ì´í„° ì‹¤ì‹œê°„ ë¡œë“œ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰")
    print("  - Answer Agent: ì¢‹ì€ ì˜ˆì‹œ(ê²Œì‹œì™„ë£Œ/ìŠ¹ì¸ë¨) 10ê°œ + ë‚˜ìœ ì˜ˆì‹œ(ì·¨ì†Œë¨) 10ê°œ")
    print("  - Query Agent: ë¶€ì ì ˆí•œ ê¸€ ì˜ˆì‹œ 20ê°œ")
    
    run_search_bot()