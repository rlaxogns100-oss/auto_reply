import time
import random
import platform
import urllib.parse 
import os 
import json
import requests
import signal
import sys
import pickle
from datetime import datetime
import google.generativeai as genai
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import UnexpectedAlertPresentException, NoAlertPresentException
import config

# ==========================================
# [DRY RUN ëª¨ë“œ]
# ==========================================
# í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´: DRY_RUN=trueë©´ ëŒ“ê¸€ì„ ì‹¤ì œë¡œ ë‹¬ì§€ ì•Šê³  ìƒì„±ë§Œ í•¨
DRY_RUN = os.environ.get("DRY_RUN", "false").lower() == "true"

# ==========================================
# [ì„œë²„ìš© ì„¤ì •]
# ==========================================
# ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
COOKIE_FILE = os.path.join(SCRIPT_DIR, "naver_cookies.pkl")
BOT_CONFIG_FILE = os.path.join(SCRIPT_DIR, "bot_config.json")
BOT_PROMPTS_FILE = os.path.join(SCRIPT_DIR, "bot_prompts.json")
COMMENT_HISTORY_FILE = os.path.join(SCRIPT_DIR, "comment_history.json")
DRY_RUN_HISTORY_FILE = os.path.join(SCRIPT_DIR, "dry_run_history.json")
SKIP_LINKS_FILE = os.path.join(SCRIPT_DIR, "skip_links.json")
STOP_FLAG_FILE = os.path.join(SCRIPT_DIR, ".stop_bot")

# Headless ëª¨ë“œ (ì„œë²„ìš©)
HEADLESS_MODE = os.environ.get("HEADLESS", "true").lower() == "true"

# ë´‡ ì¢…ë£Œ í”Œë˜ê·¸
should_stop = False

def signal_handler(signum, frame):
    """SIGTERM/SIGINT ì‹œê·¸ë„ ì²˜ë¦¬"""
    global should_stop
    print("\n[ë´‡] ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ , ì•ˆì „í•˜ê²Œ ì¢…ë£Œ ì¤‘...")
    should_stop = True

signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)

def check_stop_flag():
    """ì •ì§€ í”Œë˜ê·¸ íŒŒì¼ í™•ì¸"""
    if os.path.exists(STOP_FLAG_FILE):
        os.remove(STOP_FLAG_FILE)
        return True
    return False


def load_query_prompt():
    """bot_prompts.jsonì—ì„œ Query Agent í”„ë¡¬í”„íŠ¸ ë¡œë“œ. ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’."""
    if os.path.exists(BOT_PROMPTS_FILE):
        try:
            with open(BOT_PROMPTS_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                p = (data.get("query_prompt") or "").strip()
                if p:
                    return p
        except Exception:
            pass
    return DEFAULT_QUERY_PROMPT

def load_answer_prompt():
    """bot_prompts.jsonì—ì„œ Answer Agent í”„ë¡¬í”„íŠ¸ ë¡œë“œ. ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’."""
    if os.path.exists(BOT_PROMPTS_FILE):
        try:
            with open(BOT_PROMPTS_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                p = (data.get("answer_prompt") or "").strip()
                if p:
                    return p
        except Exception:
            pass
    return DEFAULT_ANSWER_PROMPT.strip()


def load_bot_config():
    """ë´‡ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    default_config = {
        "min_delay_seconds": 50,
        "comments_per_hour_min": 5,
        "comments_per_hour_max": 10,
        "rest_minutes": 3
    }
    if os.path.exists(BOT_CONFIG_FILE):
        try:
            with open(BOT_CONFIG_FILE, "r", encoding="utf-8") as f:
                loaded = json.load(f)
                default_config.update(loaded)
        except:
            pass
    return default_config

def save_comment_history(post_url, post_title, comment_content, success=True,
                         post_content=None, query=None, function_result=None,
                         status="pending", comment_id=None):
    """ëŒ“ê¸€ ê¸°ë¡ ì €ì¥ (ë°˜ìë™ ì‹œìŠ¤í…œìš©)
    
    Args:
        status: pending(ëŒ€ê¸°ì¤‘), approved(ìŠ¹ì¸ë¨), cancelled(ì·¨ì†Œë¨), posted(ê²Œì‹œì™„ë£Œ)
        comment_id: ê³ ìœ  ID (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
    """
    import uuid
    
    # ê°€ì‹¤í–‰ ëª¨ë“œëŠ” ë³„ë„ íŒŒì¼ì— ê¸°ë¡
    if DRY_RUN:
        history_file = DRY_RUN_HISTORY_FILE
    else:
        history_file = COMMENT_HISTORY_FILE
    
    history = []
    if os.path.exists(history_file):
        try:
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
        except:
            history = []
    
    now = datetime.now().isoformat()
    record = {
        "id": comment_id or str(uuid.uuid4()),
        "timestamp": now,
        "post_url": post_url,
        "post_title": post_title,
        "comment": comment_content,
        "success": success,
        "dry_run": DRY_RUN,
        "status": status,
        "action_history": [{"action": "created", "timestamp": now}],
        "posted_at": None
    }
    if post_content is not None:
        record["post_content"] = post_content
    if query is not None:
        record["query"] = query
    if function_result is not None:
        record["function_result"] = function_result
    history.append(record)
    
    # ìµœê·¼ 500ê°œë§Œ ìœ ì§€
    if len(history) > 500:
        history = history[-500:]
    
    with open(history_file, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)
    
    return record["id"]

def load_cookies(driver):
    """ì¿ í‚¤ íŒŒì¼ë¡œ ë¡œê·¸ì¸"""
    if not os.path.exists(COOKIE_FILE):
        print(f"[ì—ëŸ¬] ì¿ í‚¤ íŒŒì¼ ì—†ìŒ: {COOKIE_FILE}")
        print("[ì•ˆë‚´] ë¡œì»¬ì—ì„œ get_cookies.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì¿ í‚¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return False
    
    try:
        driver.get("https://naver.com")
        time.sleep(2)
        
        with open(COOKIE_FILE, "rb") as f:
            cookies = pickle.load(f)
        
        for cookie in cookies:
            # ì¼ë¶€ ì¿ í‚¤ ì†ì„± ì œê±° (í˜¸í™˜ì„±)
            if 'expiry' in cookie:
                del cookie['expiry']
            try:
                driver.add_cookie(cookie)
            except:
                pass
        
        driver.refresh()
        time.sleep(2)
        
        # ë¡œê·¸ì¸ í™•ì¸
        page_source = driver.page_source
        if "ë¡œê·¸ì•„ì›ƒ" in page_source or "ë‚´ì •ë³´" in page_source or "MY" in page_source:
            print("[ë´‡] ì¿ í‚¤ ë¡œê·¸ì¸ ì„±ê³µ!")
            return True
        else:
            print("[ì—ëŸ¬] ì¿ í‚¤ ë§Œë£Œë¨. ë‹¤ì‹œ ì¶”ì¶œí•˜ì„¸ìš”.")
            return False
            
    except Exception as e:
        print(f"[ì—ëŸ¬] ì¿ í‚¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

# ==========================================
# [ì„¤ì •] AI ëª¨ë¸ ë° API í‚¤
# ==========================================
HISTORY_FILE = os.path.join(SCRIPT_DIR, "visited_history.txt")

# config.pyì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
genai.configure(api_key=config.GEMINI_API_KEY)

# Query Agent (RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±ìš©) - gemini-2.5-flash-lite
try:
    query_agent = genai.GenerativeModel('gemini-2.5-flash-lite')
    print("[INFO] Query Agent: gemini-2.5-flash-lite")
except:
    query_agent = genai.GenerativeModel('gemini-2.0-flash')
    print("[INFO] Query Agent: gemini-2.0-flash (fallback)")

# Answer Agent (ë‹µë³€ ìƒì„±ìš©) - gemini-3-flash-preview
try:
    answer_agent = genai.GenerativeModel('gemini-3-flash-preview')
    print("[INFO] Answer Agent: gemini-3-flash-preview")
except:
    answer_agent = genai.GenerativeModel('gemini-2.5-flash')
    print("[INFO] Answer Agent: gemini-2.5-flash (fallback)")

# ê¸°ë³¸ í‚¤ì›Œë“œ (bot_config.jsonì— ì—†ì„ ë•Œ ì‚¬ìš©)
DEFAULT_KEYWORDS = [
    # 1. [í•µì‹¬] ì •ì‹œ íŒŒì´í„°ë“¤ì˜ ê³µí†µ ì–¸ì–´ (ê°€ì¥ ì¤‘ìš”)
    "ì •ì‹œ", "í‘œì ", "í‘œì¤€ì ìˆ˜", "í™˜ì‚°ì ìˆ˜", "ë°±ë¶„ìœ„",
    "ì¶”í•©", "ì˜ˆë¹„", "ìµœì´ˆí•©", "ì „ì°¬", "ì¶”ê°€í•©ê²©",
    "ìƒí–¥", "ì†Œì‹ ", "ì•ˆì •", "í•˜í–¥", "ìŠ¤ë‚˜", "ë¹µê¾¸", # 'ìŠ¤ë‚˜', 'ë¹µê¾¸'ëŠ” ê¸°íšŒë¥¼ ë…¸ë¦¬ëŠ” ì€ì–´

    # 2. [í™•ì¥] ëŒ€í•™ ë¼ì¸ (ì¤‘ìœ„ê¶Œ~ì¸ì„œìš¸ ì „ì²´ë¡œ í™•ì¥)
    "ì¸ì„œìš¸", "ìˆ˜ë„ê¶Œ", "ì§€ê±°êµ­", "ëŒ€í•™ ë¼ì¸", "ì–´ë””ê°€",
    "ê±´ë™í™", "êµ­ìˆ­ì„¸ë‹¨", "ê´‘ëª…ìƒê°€", "ì¸ê°€ê²½", "í•œì„œì‚¼", # í•™ìƒë“¤ì´ ê°€ì¥ ë§ì´ ê³ ë¯¼í•˜ëŠ” ë¼ì¸

    # 3. [ëŒ€í•™ëª…]
    "ì„œìš¸ëŒ€", "ì—°ì„¸ëŒ€", "ê³ ë ¤ëŒ€", "ì„±ê· ê´€ëŒ€", "í•œì–‘ëŒ€",
    "ì¤‘ì•™ëŒ€", "ê±´êµ­ëŒ€", "í•œêµ­ì™¸ëŒ€", "ì¤‘ëŒ€", "ê²½í¬ëŒ€",
    "ë™êµ­ëŒ€", "ëª…ì§€ëŒ€", "ì„œê°•ëŒ€", "ê´‘ìš´ëŒ€", "ì„ ë¦¬ëŒ€",
    "ìˆ­ì‹¤ëŒ€", "ì´í™”ì—¬ëŒ€"      

    # 3. ê¸°íƒ€ í‚¤ì›Œë“œ
    "ê¹Œìš”", "vs", "ê°€ëŠ¥", "ì–´ë””", "ë´ì£¼", "ì¡°ì–¸", "ìƒë‹´"
]

def load_keywords():
    """bot_config.jsonì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ë¡œë“œ. ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©."""
    if os.path.exists(BOT_CONFIG_FILE):
        try:
            with open(BOT_CONFIG_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                keywords = data.get("keywords", [])
                if keywords and len(keywords) > 0:
                    return keywords
        except Exception:
            pass
    return DEFAULT_KEYWORDS

# Backend API URL (configì—ì„œ ê°€ì ¸ì˜¤ê¸°, ê¸°ë³¸ê°’: ë¡œì»¬)
BACKEND_URL = getattr(config, 'BACKEND_URL', 'http://localhost:8000')

# ==========================================
# [ì˜¤í”„ë‹/í´ë¡œì§• ë©˜íŠ¸] ëœë¤ ì„ íƒ
# ==========================================

# ì˜¤í”„ë‹: "AIí•œí…Œ ë¬¼ì–´ë³´ë‹ˆê¹Œ ì´ë ‡ë‹¤" (ì´ˆê°„ë‹¨ ë²„ì „)
OPENINGS = [
    "ìˆ˜í—˜ìƒ ì „ë¬¸ aiì— ë¬¼ì–´ë³´ë‹ˆê¹Œ ì´ëŸ¬ë„¤ìš”",
    "ì…ì‹œ ì „ìš© ai ëŒë ¤ë³´ë‹ˆê¹Œ ì´ë ‡ê²Œ ë‚˜ì™€ìš”",
    "ë°ì´í„° í•™ìŠµëœ aií•œí…Œ ë¬¼ì–´ë³¸ ê²°ê³¼ì…ë‹ˆë‹¤",
    "ìˆ˜í—˜ìƒ aiê°€ ë¶„ì„í•œ ë‚´ìš© ê°€ì ¸ì™”ì–´ìš”",
    "ì…ì‹œ aií•œí…Œ ë¬¼ì–´ë³´ë‹ˆê¹Œ ë‹µë³€ì´ ì´ë ‡ë„¤ìš”"
]

# í´ë¡œì§•: "êµ¬ê¸€ì— uni2road ê²€ìƒ‰í•´ë¼" (ì´ˆê°„ë‹¨ ë²„ì „)
CLOSINGS = [
    "êµ¬ê¸€ì— uni2road ê²€ìƒ‰í•´ì„œ ì¨ ë³´ì„¸ìš”",
    "êµ¬ê¸€ ê²€ìƒ‰ì°½ì— uni2road ì¹˜ë©´ ë‚˜ì˜µë‹ˆë‹¤",
    "êµ¬ê¸€ì—ì„œ uni2road ê²€ìƒ‰í•´ì„œ ëŒë ¤ë³´ì„¸ìš”",
    "ìì„¸í•œê±´ êµ¬ê¸€ì— uni2road ê²€ìƒ‰í•˜ë©´ ë– ìš”",
    "ë¬´ë£Œë‹ˆê¹Œ êµ¬ê¸€ì— uni2road ê²€ìƒ‰í•´ ë³´ì„¸ìš”"
]

# ==========================================
# [Query Agent] ê²Œì‹œê¸€ ë¶„ì„ ë° RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (gemini-2.5-flash-lite)
# ==========================================
QUERY_AGENT_PROMPT = """ë‹¹ì‹ ì€ ëŒ€í•™ ì…ì‹œ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ì„ ë¶„ì„í•˜ëŠ” **Query Agent**ì…ë‹ˆë‹¤.

## ì—­í• 
ê²Œì‹œê¸€ì„ ì½ê³  **ë„ì›€ì´ í•„ìš”í•œ ìˆ˜í—˜ìƒì˜ ì§ˆë¬¸**ì¸ì§€ íŒë‹¨í•œ í›„, í•„ìš”ì‹œ RAG ê²€ìƒ‰ì„ ìœ„í•œ í•¨ìˆ˜ í˜¸ì¶œì„ ìƒì„±í•˜ì„¸ìš”.
ë‹¹ì‹ ì˜ ì—­í• ì€ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ json í˜•ì‹ì˜ í•¨ìˆ˜ í˜¸ì¶œì…ë‹ˆë‹¤. ë‹¹ì‹ ì´ ì°¾ì€ ì •ë³´ì™€ ëŒ€í™”ì˜ ë§¥ë½ì„ ì¢…í•©í•˜ì—¬ main agentê°€ ìµœì¢…ì ì¸ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
ì•„ë˜ì— ëª…ì‹œëœ ì¶œë ¥ í˜•ì‹ì„ ì§€í‚¤ì„¸ìš”. ì •í™•í•œ í•¨ìˆ˜ë¥¼ ì˜¬ë°”ë¥´ê²Œ í˜¸ì¶œí•˜ì—¬ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.

## ğŸš¨ 1ì°¨ í•„í„° - PASS í•´ì•¼ í•˜ëŠ” ê²½ìš° (ë¹ˆ ë°°ì—´ ë°˜í™˜)
ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹ë˜ë©´ function_callsë¥¼ ë¹ˆ ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
1. **ì´ë¯¸ í•©ê²©í•œ ì‚¬ëŒ**: "í•©ê²© í›„ê¸°", "ìµœì´ˆí•©", "í•©ê²©í–ˆìŠµë‹ˆë‹¤", "ëŒ€í•™ ê°‘ë‹ˆë‹¤" ë“±
2. **ì •ë³´ ê³µìœ /ìë£Œ ë°°í¬**: ì§ˆë¬¸ì´ ì•„ë‹ˆë¼ íŒì„ ì•Œë ¤ì£¼ëŠ” ê¸€, ìë£Œ ë‚˜ëˆ”ê¸€
3. **ê´‘ê³ /í™ë³´**: í•™ì› í™ë³´, ê³¼ì™¸ ëª¨ì§‘, ìŠ¤í„°ë”” ëª¨ì§‘
4. **ê³µì§€ì‚¬í•­**: ì¹´í˜ ê³µì§€, í•„ë… ë“±
5. **ë‹¨ìˆœ ì¡ë‹´**: ì—°ì• , ìœ ë¨¸, ì…ì‹œì™€ ë¬´ê´€í•œ ì¼ìƒ
6. ê³µë¶€ë²•, í•™êµìƒí™œì— ê´€í•œ ì§ˆë¬¸
7. ì´ì™¸ ê¸°íƒ€ 'ì…ì‹œìš”ê°•, ì…ê²°, ëŒ€í•™ë³„ ì ìˆ˜ í™˜ì‚°&ë¹„êµ' ìë£Œë¥¼ í†µí•´ ëŒ€ë‹µí•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸.(ì˜ˆ, í•™ì› ì¶”ì²œ, ì»¤ë¦¬ ì¶”ì²œ, ê³µë¶€ë²• ìƒë‹´, ë©˜íƒˆ ìƒë‹´ ë“±)
8. ì‹œê°„ìƒ ìœ íš¨í•˜ì§€ ì•Šì€ ì§ˆë¬¸(ì˜ˆë¥¼ ë“¤ì–´, 2026 ì…ì‹œ í•©ê²© ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì§ˆë¬¸ì€ ì´ë¯¸ ê²°ê³¼ê°€ ë‚˜ì™”ìœ¼ë¯€ë¡œ ìœ íš¨í•˜ì§€ ì•ŠìŒ.)

## 'ì…ì‹œìš”ê°•, ì…ê²°, ëŒ€í•™ë³„ ì ìˆ˜ í™˜ì‚°&ë¹„êµ' ìë£Œë¥¼ í†µí•´ ëª…í™•í•˜ê²Œ ëŒ€ë‹µ ê°€ëŠ¥í•œ ì§ˆë¬¸ë§Œ ê¹Œë‹¤ë¡­ê²Œ ì„ ì •í•˜ì„¸ìš”. ê·¸ ì™¸ ì§ˆë¬¸ì€ ëª¨ë‘ ë¹ˆ ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.



## ì‹œì  ë™ê¸°í™”
- 2026ë…„ 1ì›” (2026í•™ë…„ë„ ì…ì‹œ ì¢…ë£Œ)
- "ì˜¬í•´" = 2026í•™ë…„ë„
- "ì‘ë…„ ì…ê²°" = 2025í•™ë…„ë„
- "ë‚˜ ê³ 1ì¸ë°" -> 2028ë…„ë„ ì…ì‹œ, "ë‚˜ 18ì‚´ì¸ë°" -> 2027ë…„ë„ ì…ì‹œ(ë‚˜ì´ì— ë§ëŠ” ì…ì‹œ ìš”ê°• ìš°ì„  íƒìƒ‰)
- ì…ì‹œ ê²°ê³¼ëŠ” ìµœì‹  ìë£Œë§Œ ì‚¬ìš©(2025í•™ë…„ë„)

## ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜

### univ(university, query)
íŠ¹ì • ëŒ€í•™ì˜ ì…ì‹œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
- university: ëŒ€í•™ ì •ì‹ëª…ì¹­ (ì„œìš¸ëŒ€í•™êµ, ê²½í¬ëŒ€í•™êµ)
- query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì—°ë„ + ì „í˜• + í•™ê³¼ ëª…ì‹œ)

ì˜ˆì‹œ:
- "ì„œìš¸ëŒ€ ê°€ëŠ” ë²•" -> univ("ì„œìš¸ëŒ€í•™êµ", "ì„œìš¸ëŒ€í•™êµ 2026í•™ë…„ë„ ëª¨ì§‘ìš”ê°•")
- "ì„œìš¸ëŒ€ ê¸°ê³„ê³¼ ì •ì‹œ" â†’ univ("ì„œìš¸ëŒ€í•™êµ", "2026í•™ë…„ë„ ê¸°ê³„ê³µí•™ë¶€ ì •ì‹œ")
- "ë‚˜ ê³ 1ì¸ë° ê²½í¬ëŒ€ ë†ì–´ì´Œ ì „í˜• ì•Œë ¤ì¤˜" â†’ univ("ê²½í¬ëŒ€í•™êµ", "2028 ê²½í¬ëŒ€í•™êµ ë†ì–´ì´Œ ì „í˜•")

### consult(scores, target_univ, target_major, target_range)
ëŒ€í•™ ì…ê²° ì¡°íšŒ, í•™ìƒ ì„±ì  ëŒ€í•™ë³„ í™˜ì‚°ì ìˆ˜ ë³€í™˜, í•©ê²© ê°€ëŠ¥ì„± í‰ê°€
í•™ìƒ ì„±ì ì„ ë¶„ì„í•˜ì—¬ í•©ê²© ê°€ëŠ¥ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. í™˜ì‚°ì ìˆ˜ ê³„ì‚° í¬í•¨.
#### ì£¼ì˜: ì„±ì  ì •ë³´ê°€ ì§ˆë¬¸ì— ìˆìœ¼ë©´ scores ë¡œ ì‚¬ìš©, ì§ˆë¬¸ì— ì—†ê³  historyì— ìˆìœ¼ë©´ ê·¸ ì •ë³´ë¥¼ scores ë¡œ ì‚¬ìš©, ë‘˜ ë‹¤ ì—†ìœ¼ë©´ consult í˜¸ì¶œ ì•ˆ í•¨
- scores: ì„±ì  ë”•ì…”ë„ˆë¦¬ {"êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1}, ...}
- target_univ: ë¶„ì„ ëŒ€ìƒ ëŒ€í•™ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ [])
- target_major: ê´€ì‹¬ í•™ê³¼ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ [])
- target_range: ë¶„ì„ ë²”ìœ„ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ [] = ì „ì²´ ë²”ìœ„)

#### ì„±ì  ì…ë ¥ í˜•ì‹
1. ì¶•ì•½í˜• (5ìë¦¬): "11232" â†’ êµ­ì–´/ìˆ˜í•™/ì˜ì–´/íƒêµ¬1/íƒêµ¬2 ë“±ê¸‰
2. ì¶•ì•½í˜• (6ìë¦¬): "211332" â†’ í•œêµ­ì‚¬/êµ­ì–´/ìˆ˜í•™/ì˜ì–´/íƒêµ¬1/íƒêµ¬2 ë“±ê¸‰
3. ë“±ê¸‰: "êµ­ì–´ 1ë“±ê¸‰", "ìˆ˜í•™ 2ë“±ê¸‰"
4. í‘œì¤€ì ìˆ˜: "ìˆ˜í•™ 140ì ", "ìˆ˜í•™ í‘œì¤€ì ìˆ˜ 140"
5. ë°±ë¶„ìœ„: "êµ­ì–´ ë°±ë¶„ìœ„ 98"

#### ê³¼ëª©ëª… ì²˜ë¦¬
- ì¼ë°˜ ê³¼ëª©ëª… (ì„ íƒê³¼ëª© ë¯¸ì–¸ê¸‰): êµ­ì–´, ìˆ˜í•™, ì˜ì–´, í•œêµ­ì‚¬, íƒêµ¬1, íƒêµ¬2 â†’ ê·¸ëŒ€ë¡œ ì¶œë ¥
- êµ¬ì²´ì  ì„ íƒê³¼ëª© (ëª…ì‹œëœ ê²½ìš°): í™”ë²•ê³¼ì‘ë¬¸(í™”ì‘), ì–¸ì–´ì™€ë§¤ì²´(ì–¸ë§¤), ë¯¸ì ë¶„, í™•ë¥ ê³¼í†µê³„(í™•í†µ), ê¸°í•˜, ìƒëª…ê³¼í•™1(ìƒ1), ì§€êµ¬ê³¼í•™1(ì§€1), ìƒí™œê³¼ìœ¤ë¦¬(ìƒìœ¤), ì‚¬íšŒë¬¸í™”(ì‚¬ë¬¸) ë“± â†’ ê³¼ëª©ëª… ê·¸ëŒ€ë¡œ ì¶œë ¥
- ì„±ì ì´ ì¶”ì • ê°€ëŠ¥í•œ ê²½ìš°ì—ëŠ” ì„ì˜ë¡œ ì¶”ì •í•˜ì—¬ ì¶œë ¥: "êµ­ì–´ ì˜ì–´ëŠ” 1ì¸ë° ìˆ˜í•™ì€ ì¢€ ëª»í•´ìš” -> 3ë“±ê¸‰ìœ¼ë¡œ ì¶”ì •"

#### ì„±ì  ì¶œë ¥ í˜•ì‹
```json
{
  "scores": {
    "êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1},
    "ìˆ˜í•™": {"type": "í‘œì¤€ì ìˆ˜", "value": 140},
    "ì˜ì–´": {"type": "ë“±ê¸‰", "value": 2},
    "í•œêµ­ì‚¬": {"type": "ë“±ê¸‰", "value": 1},
    "íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 1, "ê³¼ëª©ëª…": "ìƒí™œê³¼ìœ¤ë¦¬"},
    "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 2, "ê³¼ëª©ëª…": "ì‚¬íšŒë¬¸í™”"}
  }
}
```
- type: "ë“±ê¸‰", "í‘œì¤€ì ìˆ˜", "ë°±ë¶„ìœ„"
- íƒêµ¬ ê³¼ëª©ì€ í‚¤ë¥¼ "íƒêµ¬1", "íƒêµ¬2"ë¡œ ê³ ì •í•˜ê³ , ê³¼ëª©ëª…ì´ ì–¸ê¸‰ëœ ê²½ìš° "ê³¼ëª©ëª…" í•„ë“œ ì¶”ê°€
- í•œêµ­ì‚¬ëŠ” í•­ìƒ í¬í•¨ (ë¯¸ì–¸ê¸‰ ì‹œ 1ë“±ê¸‰ìœ¼ë¡œ ê¸°ë³¸ ì¶”ì •)

ì„±ì  ì˜ˆì‹œ:
- "11232" â†’ {"êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1}, "ìˆ˜í•™": {"type": "ë“±ê¸‰", "value": 1}, "ì˜ì–´": {"type": "ë“±ê¸‰", "value": 2}, "í•œêµ­ì‚¬": {"type": "ë“±ê¸‰", "value": 1}, "íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 3}, "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 2}}
- "êµ­ì–´ í™”ì‘ 1ë“±ê¸‰, ìˆ˜í•™ ë¯¸ì  140ì " â†’ {"êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1, "ì„ íƒê³¼ëª©": "í™”ë²•ê³¼ì‘ë¬¸"}, "ìˆ˜í•™": {"type": "í‘œì¤€ì ìˆ˜", "value": 140, "ì„ íƒê³¼ëª©": "ë¯¸ì ë¶„"}}
- "ìƒìœ¤ 2ë“±ê¸‰ ì‚¬ë¬¸ 1ë“±ê¸‰" â†’ {"íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 2, "ê³¼ëª©ëª…": "ìƒí™œê³¼ìœ¤ë¦¬"}, "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 1, "ê³¼ëª©ëª…": "ì‚¬íšŒë¬¸í™”"}}
- "ë¬¼1 ì§€1 1ë“±ê¸‰" â†’ {"íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 1, "ê³¼ëª©ëª…": "ë¬¼ë¦¬í•™1"}, "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 1, "ê³¼ëª©ëª…": "ì§€êµ¬ê³¼í•™1"}}

target_range ì˜µì…˜ (ìƒˆë¡œìš´ íŒì • ê¸°ì¤€):
- ["ì•ˆì •"]: ë‚´ ì ìˆ˜ >= ì•ˆì •ì»· (safeScore), í•©ê²© í™•ë¥  ë§¤ìš° ë†’ìŒ
- ["ì ì •"]: ë‚´ ì ìˆ˜ >= ì ì •ì»· (appropriateScore), í•©ê²© ê°€ëŠ¥ì„± ë†’ìŒ
- ["ì†Œì‹ "]: ë‚´ ì ìˆ˜ >= ì†Œì‹ ì»· (expectedScore), í•©ê²© ê°€ëŠ¥ì„± ìˆìŒ
- ["ë„ì „"]: ë‚´ ì ìˆ˜ >= ë„ì „ì»· (challengeScore), ë„ì „ì ì¸ ì§€ì›
- ["ì–´ë ¤ì›€"]: ë‚´ ì ìˆ˜ < ë„ì „ì»·, í•©ê²© ì–´ë ¤ì›€
- []: ë¹ˆ ë°°ì—´ = ëª¨ë“  ë²”ìœ„ (ê¸°ë³¸ê°’), scoreê°€ ì£¼ì–´ì§€ì§€ ì•Šìœ¼ë©´ í•­ìƒ ë¹ˆ ë°°ì—´
- í•™ìƒì´ ìê¸° ì„±ì ë§Œ ì…ë ¥í•œ ê²½ìš° -> [ì•ˆì •, ì ì •, ì†Œì‹ ]
ì˜ˆì‹œ:
- "ë‚˜ 11232ì¸ë° ê²½í¬ëŒ€ ê°ˆ ìˆ˜ ìˆì–´?" â†’ consult(scores, ["ê²½í¬ëŒ€í•™êµ"], [], [])
- "11112ë¡œ ê¸°ê³„ê³µí•™ ì–´ë”” ê°ˆê¹Œ?" â†’ consult(scores, [], ["ê¸°ê³„ê³µí•™"], [ì•ˆì •, ì ì •, ì†Œì‹ ])
- 'ë‚´ ì„±ì  ì–¸ë§¤ 99, ë¯¸ì  100, ì˜ì–´ 1ë“±ê¸‰, ë¬¼1 85, í™”2 93ì´ì•¼: -> consult(scores, [], [], [ì•ˆì •, ì ì •, ì†Œì‹ ])
- "ì ì • ëŒ€í•™ ì¶”ì²œí•´ì¤˜" â†’ consult(scores, [], [], ["ì ì •"])
- "ë„ì „ìœ¼ë¡œ ì„œìš¸ëŒ€ ì—°ì„¸ëŒ€ ê°€ëŠ¥í•´?" â†’ consult(scores, ["ì„œìš¸ëŒ€í•™êµ", "ì—°ì„¸ëŒ€í•™êµ"], [], ["ë„ì „"])

## ì¶œë ¥ í˜•ì‹
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì ˆëŒ€ ê¸ˆì§€.

### ë‹¨ì¼ í•¨ìˆ˜ í˜¸ì¶œ ì˜ˆì‹œ (ì˜¬í•´ ìˆ˜ëŠ¥ìœ¼ë¡œ ì„œìš¸ëŒ€ ê°€ë ¤ë©´ ì–´ë–»ê²Œ í•´?)
```json
{
  "function_calls": [
    {
      "function": "univ",
      "params": {
        "university": "ì„œìš¸ëŒ€í•™êµ",
        "query": "2026í•™ë…„ë„ ì„œìš¸ëŒ€í•™êµ ì •ì‹œ ëª¨ì§‘ìš”ê°•", "2025í•™ë…„ë„ ì„œìš¸ëŒ€í•™êµ ì •ì‹œ ì…ê²°"
      }
    }
  ]
}
```

### ì„±ì  ë¶„ì„ ì˜ˆì‹œ (ë‚˜ 11232ì¸ë° ê²½í¬ëŒ€ ê°ˆ ìˆ˜ ìˆì–´?)
```json
{
  "function_calls": [
    {
      "function": "consult",
      "params": {
        "scores": {
          "êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1},
          "ìˆ˜í•™": {"type": "ë“±ê¸‰", "value": 1},
          "ì˜ì–´": {"type": "ë“±ê¸‰", "value": 2},
          "íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 3},
          "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 2}
        },
        "target_univ": ["ê²½í¬ëŒ€í•™êµ"],
        "target_major": [],
        "target_range": []
      }
    },
    {
      "function": "univ",
      "params": {
        "university": "ê²½í¬ëŒ€í•™êµ",
        "query": "2026í•™ë…„ë„ ê²½í¬ëŒ€í•™êµ ì •ì‹œ ëª¨ì§‘ìš”ê°•"
      }
    }
  ]
}
```

### ì ì • ëŒ€í•™ ì¶”ì²œ ì˜ˆì‹œ (11112ì¸ë° ì ì • ëŒ€í•™ ì¶”ì²œí•´ì¤˜)
```json
{
  "function_calls": [
    {
      "function": "consult",
      "params": {
        "scores": {
          "êµ­ì–´": {"type": "ë“±ê¸‰", "value": 1},
          "ìˆ˜í•™": {"type": "ë“±ê¸‰", "value": 1},
          "ì˜ì–´": {"type": "ë“±ê¸‰", "value": 1},
          "íƒêµ¬1": {"type": "ë“±ê¸‰", "value": 1},
          "íƒêµ¬2": {"type": "ë“±ê¸‰", "value": 2}
        },
        "target_univ": [],
        "target_major": [],
        "target_range": ["ì ì •"]
      }
    }
  ]
}
```

## íŒë‹¨ ê·œì¹™
1. **ëŒ€í•™ëª… ì •ê·œí™”**: ì„œìš¸ëŒ€ â†’ ì„œìš¸ëŒ€í•™êµ, ê³ ëŒ€ â†’ ê³ ë ¤ëŒ€í•™êµ
2. **ì—°ë„ ëª…ì‹œ**: í•­ìƒ "XXXXí•™ë…„ë„" í¬í•¨
3. **ì„±ì  ì§ˆë¬¸**: ì„±ì  + íŠ¹ì • ëŒ€í•™ ì–¸ê¸‰ ì‹œ consult + univ ë™ì‹œ í˜¸ì¶œ
4. **ëŒ€í•™ëª… ì–¸ê¸‰ ì—†ëŠ” ë§‰ì—°í•œ ì§ˆë¬¸ì—ëŠ” consult í˜¸ì¶œ**:  
    - "ë‚´ ì„±ì (ì–¸ê¸‰)ìœ¼ë¡œ ì–´ë”” ê°ˆ ìˆ˜ ìˆì–´?" â†’ consult(scores, [], [], [ì•ˆì •, ì ì •, ì†Œì‹ ])
    - "ë©”ë””ì»¬ ê°€ë ¤ë©´ ê³µë¶€ ì–¼ë§ˆë‚˜ í•´ì•¼ í•´?" â†’ consult(scores, [], ['ì˜ì˜ˆê³¼', 'ì¹˜ì˜ˆê³¼', 'í•œì˜ì˜ˆê³¼', 'ìˆ˜ì˜ì˜ˆê³¼', 'ì•½í•™ê³¼'], [])
5. **ë¹„êµ ì§ˆë¬¸**: ì—¬ëŸ¬ ëŒ€í•™ ë¹„êµ ì‹œ ê°ê° univ í˜¸ì¶œ
6. **ê¸°ë³¸ê°’ì€ ë¹ˆ ë°°ì—´**: target_univ, target_major, target_range ëª¨ë‘ ëª…ì‹œ ì•ˆë˜ë©´ []
7. **ì •í™•í•œ ì˜ë„ íŒŒì•…**: 
    - "ê·¸ë˜ë„ ì–´ë””ê¹Œì§„ í™•ì‹¤íˆ ë ê¹Œ?" -> consult(scores, [], [], ["ì ì •", "ì•ˆì •"]), 
    - "ì–´ë””ê¹Œì§€ ê°ˆ ìˆ˜ ìˆì„ê¹Œ?" -> consult(scores, [], [], ["ë„ì „", "ì†Œì‹ "])
8. ì• ë§¤í•˜ë©´ í¬ê´„ì ìœ¼ë¡œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°(ì–´ì§œí”¼ main agentì—ì„œ ì •ë³´ ì„ ë³„, ë‹¨ ìµœëŒ€ í˜¸ì¶œ ìˆ˜ 3ê°œë¡œ ì œí•œ)
    - "ìˆ˜ë„ê¶Œ ê³µëŒ€ ì¤‘ì— 2ë“±ê¸‰ì´ ê°ˆ ê³³ ì•Œë ¤ì¤˜" -> consult(scores, [], [ê³µí•™], ["ì ì •", "ì•ˆì •"]) (ìˆ˜ë„ê¶Œì€ ë³€ìˆ˜ ì„¤ì •ì´ ì•ˆ ë˜ì§€ë§Œ, ëª¨ë“  ê³µëŒ€ì— ëŒ€í•´ì„œ ì¡°ì‚¬í•˜ë©´ main agentê°€ ì„ ë³„), 
    - "SKY ì¤‘ì— ê³µëŒ€ 1000ëª… ë„˜ê²Œ ë½‘ëŠ” ê³³ ì•Œë ¤ì¤˜ -> ì„œìš¸ëŒ€, ì—°ì„¸ëŒ€, ê³ ë ¤ëŒ€ ì „ë¶€ í˜¸ì¶œ

"""

# Query Agent ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ê´€ë¦¬ í˜ì´ì§€ì—ì„œ ìˆ˜ì • ê°€ëŠ¥)
DEFAULT_QUERY_PROMPT = QUERY_AGENT_PROMPT.strip()

# Answer Agent ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ê´€ë¦¬ í˜ì´ì§€ì—ì„œ ìˆ˜ì • ê°€ëŠ¥)
DEFAULT_ANSWER_PROMPT = """
[ì‘ì„± ì „ëµ: ì² ì €í•œ ë°ì´í„° ê¸°ë°˜ì˜ ì»¨ì„¤íŒ…]

0. **ìµœìš°ì„  ê·œì¹™**
    - í•™ìƒì˜ ì§ˆë¬¸ ë§¥ë½ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•´ì„œ ëŒ€ë‹µí•˜ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì •ë³´ ì¸ìš©, ë§¥ë½ìƒ ì–´ìƒ‰í•œ ë‹µë³€ì€ ì ˆëŒ€ë¡œ í•˜ì§€ ë§ˆì„¸ìš”.
    - í•™ìƒì˜ ì ìˆ˜(ì›ì ìˆ˜, ë°±ë¶„ìœ„, ë“±ê¸‰ ë“±)ì€ ë³¸ë¬¸ì— ìˆëŠ” ì ìˆ˜ë§Œ ì¸ìš©í•˜ì„¸ìš”, [ğŸ“š ê´€ë ¨ ì…ì‹œ ì •ë³´ (RAG)]ì—ì„œ í™˜ì‚°ëœ ë°±ë¶„ìœ„ëŠ” ì ˆëŒ€ ì¸ìš©í•˜ì§€ ë§ˆì„¸ìš”, ëŒ€í•™ë³„ í™˜ì‚° ì ìˆ˜ë§Œ ì¸ìš©í•´ë„ ë©ë‹ˆë‹¤.

1. **ğŸ¯ í•µì‹¬ ê°€ì¹˜ (Value Proposition)**
   - **ë¬´ì¡°ê±´ 'ìˆ«ì'ë¡œ ëŒ€ë‹µ:** RAGë¡œ ê°€ì ¸ì˜¨ **'ì‘ë…„ ì…ê²°(70% ì»·)', 'í™˜ì‚° ì ìˆ˜', 'ëª¨ì§‘ ì¸ì› ë³€í™”'** ë“± êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ ë°˜ë“œì‹œ í•˜ë‚˜ ì´ìƒ ì¸ìš©í•´.
   - **ì •ì‹œ/êµê³¼ íŒŒì´í„° ëª¨ë“œ:** ì§ˆë¬¸ìì˜ ì„±ì ì´ ì• ë§¤í•˜ë©´ "ì´ ì ìˆ˜ë©´ OOëŒ€ëŠ” ìœ„í—˜í•˜ê³  â–³â–³ëŒ€ê°€ ì°¨ë¼ë¦¬ ë‚«ë‹¤"ëŠ” ì‹ìœ¼ë¡œ **ëŒ€ì•ˆì„ ì œì‹œ**í•˜ê±°ë‚˜ **í•©ê²© ê°€ëŠ¥ì„±ì„ ëƒ‰ì •í•˜ê²Œ ì§„ë‹¨**í•´.
   - **ë‚´ìš©:** "ìœ ë¦¬í•˜ë‹¤" ê°™ì€ ëª¨í˜¸í•œ í‘œí˜„ ëŒ€ì‹ , "ì‘ë…„ ì»·(392ì )ë³´ë‹¤ 3ì  ë†’ì•„ ì•ˆì •ì ì´ì—ìš”", "í•´ë‹¹ ëŒ€í•™ì—ì„œ ê°€ì¥ ë‚®ì€ ì»·(ì‹¬ë¦¬í•™ê³¼, 395ì )ë³´ë‹¤ 2ì  ë‚®ì•„ ì–´ë ¤ì›Œìš”."ì²˜ëŸ¼ **ìˆ˜ì¹˜ ì¤‘ì‹¬**ìœ¼ë¡œ ì„¤ëª….

2. **ğŸ—£ï¸ í†¤ì•¤ë§¤ë„ˆ (Tone & Manner)**
   - **ë§íˆ¬:** "~í•´ìš”"ì²´ ì‚¬ìš©í•˜ë˜, ìì‹ ê° ìˆê³  í™•ì‹ ì— ì°¬ ì–´ì¡°. (ì¹œì ˆí•œ ì„ ë°° ë§íˆ¬, ë¬´ë¡€í•˜ì§€ ì•Šê²Œ.)
   - **ê¸¸ì´:** 3~4ë¬¸ì¥. (ì„œë¡  ë¹¼ê³  ë³¸ë¡ ë§Œ ë”±.)

3. **ì¶œë ¥ í˜•ì‹:** ëŒ“ê¸€ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
   - **ë‹¤ë¥¸ ë§ ì—†ì´ ëŒ“ê¸€ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”**
   - **ë§ˆí¬ë‹¤ìš´ í˜•ì‹(**, ##, > ë“±) ì‚¬ìš© ê¸ˆì§€.** í‰ë¬¸(Plain Text)ë§Œ ì‚¬ìš©.
   - **ì¤‘ìš”** ìœ„ [ğŸ“š ê´€ë ¨ ì…ì‹œ ì •ë³´ (RAG)] ë¸”ë¡ì— ì íŒ ìˆ˜ì¹˜(ì…ê²°, ì»·, í™˜ì‚°ì ìˆ˜, ëª¨ì§‘ì¸ì› ë“±)ë¥¼ ê·¼ê±°ë¡œ í•œ ë‹µë³€ì´ ì•„ë‹ ê²½ìš°ì—ëŠ” ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”, ìë£Œì— ê·¼ê±°í•˜ì§€ ì•Šê³  ìì²´ ìƒì„±í•˜ëŠ” ëŒ“ê¸€ì€ ì ˆëŒ€ë¡œ ë‹¬ì§€ ë§ˆì„¸ìš”.
   - **ì¤‘ìš”** ìƒì„±í•œ ëŒ“ê¸€ì´ ëª…í™•í•˜ê²Œ ë„ì›€ë˜ì§€ ì•Šê±°ë‚˜, í•™ìƒì´ ê³µê²©ì ìœ¼ë¡œ ëŠë‚„ ìˆ˜ ìˆë‹¤ê³  ëŠê»´ì§€ë©´ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”.
"""

def generate_function_calls(title, content):
    """
    Query Agentë¡œ ê²Œì‹œê¸€ ë¶„ì„ ë° í•¨ìˆ˜ í˜¸ì¶œ ìƒì„±
    
    Returns:
        list: function_calls ë°°ì—´ (PASSì¸ ê²½ìš° ë¹ˆ ë°°ì—´)
        None: ì—ëŸ¬ ë°œìƒ ì‹œ
    """
    try:
        query_instruction = load_query_prompt()
        prompt = f"""{query_instruction}

[ê²Œì‹œê¸€]
ì œëª©: {title}
ë³¸ë¬¸: {content[:1000]}

ìœ„ ê²Œì‹œê¸€ì„ ë¶„ì„í•˜ì—¬ function_callsë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.
"""
        
        generation_config = {
            "temperature": 0.0,
            "max_output_tokens": 2048,
            "response_mime_type": "application/json"
        }
        
        response = query_agent.generate_content(prompt, generation_config=generation_config)
        result_text = response.text.strip()
        
        # JSON íŒŒì‹±
        result = json.loads(result_text)
        function_calls = result.get("function_calls", [])
        
        if not function_calls:
            print(f"  -> [Query Agent] PASS (ë„ì›€ ë¶ˆí•„ìš”)")
            return []
        
        print(f"  -> [Query Agent] {len(function_calls)}ê°œ í•¨ìˆ˜ í˜¸ì¶œ ìƒì„±")
        for call in function_calls:
            print(f"     - {call.get('function')}: {call.get('params', {}).get('university', '')} {call.get('params', {}).get('query', '')[:50]}")
        
        return function_calls
        
    except json.JSONDecodeError as e:
        print(f"  -> [Query Agent] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"     ì›ë³¸: {result_text[:200]}")
        return None
    except Exception as e:
        print(f"  -> [Query Agent] ì—ëŸ¬: {e}")
        return None


# ==========================================
# [RAG] Backend API í˜¸ì¶œë¡œ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
# ==========================================
def get_rag_context_from_functions(function_calls):
    """
    function_callsë¥¼ Backend APIë¡œ ì „ì†¡í•˜ì—¬ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        function_calls: Query Agentê°€ ìƒì„±í•œ function_calls ë°°ì—´
        
    Returns:
        dict: RAG ê²€ìƒ‰ ê²°ê³¼ (chunks, document_titles ë“±)
        None: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
    """
    if not function_calls:
        return None
        
    try:
        # Backend API í˜¸ì¶œ
        response = requests.post(
            f"{BACKEND_URL}/api/functions/execute",
            json={"function_calls": function_calls},
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if result.get("success"):
                print(f"  -> [RAG API] ì‘ë‹µ ì„±ê³µ")
                return result.get("results", {})
        
        print(f"  -> [RAG API] ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        return None
        
    except requests.exceptions.ConnectionError:
        print(f"  -> [RAG API] ì—°ê²° ì‹¤íŒ¨ - Backend ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš” ({BACKEND_URL})")
        return None
    except requests.exceptions.Timeout:
        print("  -> [RAG API] íƒ€ì„ì•„ì›ƒ")
        return None
    except Exception as e:
        print(f"  -> [RAG API ì—ëŸ¬] {e}")
        return None


def format_rag_context(rag_results):
    """
    RAG ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    """
    if not rag_results:
        print("  -> [RAG] rag_resultsê°€ ë¹„ì–´ìˆìŒ")
        return ""
    
    context_parts = []
    
    print(f"  -> [RAG DEBUG] rag_results keys: {list(rag_results.keys())}")
    
    for key, result in rag_results.items():
        chunks = result.get("chunks", [])
        print(f"  -> [RAG DEBUG] {key}: {len(chunks)}ê°œ ì²­í¬")
        
        if not chunks:
            continue
        
        # ì²« ë²ˆì§¸ ì²­í¬ êµ¬ì¡° í™•ì¸
        if chunks:
            first_chunk = chunks[0]
            print(f"  -> [RAG DEBUG] ì²« ì²­í¬ keys: {list(first_chunk.keys())}")
            print(f"  -> [RAG DEBUG] ì²« ì²­í¬ content ê¸¸ì´: {len(first_chunk.get('content', ''))}")
        
        context_parts.append(f"\n=== ê´€ë ¨ ì…ì‹œ ì •ë³´ ({result.get('university', 'ì „ì²´')}) ===")
        
        for i, chunk in enumerate(chunks[:10], 1):  # ìƒìœ„ 10ê°œ ì²­í¬ ì‚¬ìš©
            content = chunk.get("content", "")  # ì „ì²´ ë‚´ìš© ì „ë‹¬ (ì œí•œ ì œê±°)
            context_parts.append(f"[{i}] {content}")
    
    final_context = "\n".join(context_parts) if context_parts else ""
    print(f"  -> [RAG DEBUG] ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(final_context)}ì")
    return final_context


# ==========================================
# [í•µì‹¬] ê²Œì‹œê¸€ ë¶„ì„ ë° ë‹µë³€ ìƒì„±
# ==========================================
def analyze_and_generate_reply(title, content, use_rag=True):
    try:
        # Query Agentë¡œ ê²Œì‹œê¸€ ë¶„ì„ ë° function_calls ìƒì„±
        print("  -> [Query Agent] ê²Œì‹œê¸€ ë¶„ì„ ì¤‘...")
        function_calls = generate_function_calls(title, content)
        
        if function_calls is None:
            # ì—ëŸ¬ ë°œìƒ
            print("  -> [Query Agent] ì—ëŸ¬ - ê¸°ë³¸ PASS ì²˜ë¦¬")
            return None
        
        if not function_calls:
            # PASS (ë„ì›€ ë¶ˆí•„ìš”í•œ ê²Œì‹œê¸€)
            return None
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        rag_context = ""
        if use_rag:
            print("  -> [RAG] Backend API í˜¸ì¶œ ì¤‘...")
            rag_results = get_rag_context_from_functions(function_calls)
            if rag_results:
                rag_context = format_rag_context(rag_results)
                print(f"  -> [RAG] ì»¨í…ìŠ¤íŠ¸ {len(rag_context)}ì ë¡œë“œ ì™„ë£Œ")
            else:
                print("  -> [RAG] ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰)")
        
        # RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        rag_section = ""
        if rag_context:
            rag_section = f"""
        [ğŸ“š ê´€ë ¨ ì…ì‹œ ì •ë³´ (RAG)]
        ì•„ë˜ëŠ” ê²Œì‹œê¸€ê³¼ ê´€ë ¨ëœ ê³µì‹ ì…ì‹œ ì •ë³´ì…ë‹ˆë‹¤. ë‹µë³€ ì‹œ ì°¸ê³ í•˜ì„¸ìš”.
        {rag_context}
        """
        
        instruction = load_answer_prompt()
        prompt = f"""
        ë‹¹ì‹ ì€ ìˆ˜ë§Œíœ˜ ì…ì‹œ ì»¤ë®¤ë‹ˆí‹°ì˜ ì…ì‹œ ë©˜í† ì…ë‹ˆë‹¤.
        ê²Œì‹œê¸€ì„ ì½ê³  ë„ì›€ì´ ë˜ëŠ” ëŒ“ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.

        [ê²Œì‹œê¸€ ì •ë³´]
        ì œëª©: {title}
        ë³¸ë¬¸: {content[:1000]}
        {rag_section}
        {instruction}
        """
        
        # Answer Agentë¡œ ë‹µë³€ ìƒì„± (gemini-3-flash-preview)
        response = answer_agent.generate_content(prompt)
        result = (response.text or "").strip()
        result = result.replace('"', '').replace("'", "")  # ë”°ì˜´í‘œ ì œê±°
        result = result.strip()
        
        # í•  ë§ ì—†ê±°ë‚˜ 20ì ì´í•˜ë©´ ëŒ“ê¸€ ì•ˆ ë‹¬ê³  ë„˜ì–´ê° (ë¹ˆ ë°°ì—´/ì§§ì€ ë¬´ì˜ë¯¸ ì‘ë‹µ ì°¨ë‹¨)
        if not result or len(result) <= 20:
            print(f"  -> [Answer Agent] í•  ë§ ì—†ìŒ/ì§§ìŒ ({len(result)}ì) - PASS (ëŒ“ê¸€ ìƒëµ)")
            return None
        
        # ëœë¤ ì˜¤í”„ë‹/í´ë¡œì§• ì„ íƒ
        opening = random.choice(OPENINGS)
        closing = random.choice(CLOSINGS)
        
        # ê³ ì • í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        formatted_reply = f"""{opening}

{result}

{closing}""" 
        
        # ê´€ë¦¬ í˜ì´ì§€ 5ì—´(ì›ê¸€/ì¿¼ë¦¬/í•¨ìˆ˜ê²°ê³¼/ìµœì¢…ë‹µë³€/ë§í¬) ì €ì¥ìš©
        extra = {
            "post_content": (title or "") + "\n\n" + (content or "")[:2000],
            "query": json.dumps(function_calls, ensure_ascii=False),
            "function_result": rag_context or ""
        }
        return (formatted_reply, extra)
            
    except Exception as e:
        print(f"  -> [AI ì—ëŸ¬] {e}")
        return None

# ==========================================
# [ê¸°ë³¸ í•¨ìˆ˜]
# ==========================================
def load_history():
    if not os.path.exists(HISTORY_FILE): return set()
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return set(line.strip() for line in f.readlines())
    except: return set()

def append_history(link):
    """ë°©ë¬¸ ê¸°ë¡ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€) - ê°€ì‹¤í–‰ ëª¨ë“œëŠ” ê¸°ë¡ ì•ˆ í•¨"""
    # ê°€ì‹¤í–‰ ëª¨ë“œëŠ” visited_historyì— ê¸°ë¡í•˜ì§€ ì•ŠìŒ
    if DRY_RUN:
        return
    
    try:
        # ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
        existing = load_history()
        if link in existing:
            return  # ì´ë¯¸ ìˆìœ¼ë©´ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
        with open(HISTORY_FILE, "a", encoding="utf-8") as f:
            f.write(link + "\n")
    except: pass


def extract_article_id(url):
    """URLì—ì„œ article ID ì¶”ì¶œ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
    
    ì§€ì› í˜•ì‹:
    - https://cafe.naver.com/f-e/cafes/10197921/articles/29429119
    - https://cafe.naver.com/suhui/29429119
    - https://cafe.naver.com/suhui/29429119?art=...
    """
    import re
    # ìˆ«ìë§Œ ì¶”ì¶œ (ë§ˆì§€ë§‰ ìˆ«ì ê·¸ë£¹ì´ article ID)
    # f-e í˜•ì‹: /articles/29429119
    match = re.search(r'/articles/(\d+)', url)
    if match:
        return match.group(1)
    
    # ì¼ë°˜ í˜•ì‹: /ì¹´í˜ëª…/29429119 ë˜ëŠ” /ì¹´í˜ëª…/29429119?...
    match = re.search(r'/([a-zA-Z0-9_]+)/(\d+)(?:\?|$)', url)
    if match:
        return match.group(2)
    
    return None


def is_already_commented(link):
    """comment_history.json ë° skip_links.jsonì—ì„œ ì´ë¯¸ ì²˜ë¦¬í•œ ê¸€ì¸ì§€ í™•ì¸"""
    # ê°€ì‹¤í–‰ ëª¨ë“œì—ì„œëŠ” ì¤‘ë³µ ì²´í¬ ì•ˆ í•¨
    if DRY_RUN:
        return False
    
    # ì…ë ¥ ë§í¬ì—ì„œ article ID ì¶”ì¶œ
    input_article_id = extract_article_id(link)
    if not input_article_id:
        # ID ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¹„êµ
        input_article_id = link
    
    # 1. comment_history.json ì²´í¬
    if os.path.exists(COMMENT_HISTORY_FILE):
        try:
            with open(COMMENT_HISTORY_FILE, "r", encoding="utf-8") as f:
                history = json.load(f)
                for item in history:
                    stored_url = item.get("post_url", "")
                    stored_article_id = extract_article_id(stored_url) or stored_url
                    
                    # article IDë¡œ ë¹„êµ
                    if stored_article_id == input_article_id and item.get("success"):
                        return True
        except:
            pass
    
    # 2. skip_links.json ì²´í¬ (ìˆ˜ë™ ìŠ¤í‚µ ë§í¬)
    if os.path.exists(SKIP_LINKS_FILE):
        try:
            with open(SKIP_LINKS_FILE, "r", encoding="utf-8") as f:
                skip_links = json.load(f)
                for item in skip_links:
                    if item.get("article_id") == input_article_id:
                        print(f"  -> [Skip] ìˆ˜ë™ ìŠ¤í‚µ ë§í¬ì…ë‹ˆë‹¤.")
                        return True
        except:
            pass
    
    return False

# ==========================================
# [í¬ë¡¤ëŸ¬ ë´‡] - ë°˜ìë™ ì‹œìŠ¤í…œ: ëŒ“ê¸€ ìƒì„±ë§Œ í•˜ê³  pending ìƒíƒœë¡œ ì €ì¥
# ==========================================
def run_search_bot():
    """í¬ë¡¤ëŸ¬ ë´‡: ê²Œì‹œê¸€ì„ ë¹ ë¥´ê²Œ íƒìƒ‰í•˜ê³  ëŒ“ê¸€ì„ ìƒì„±í•˜ì—¬ pending ìƒíƒœë¡œ ì €ì¥"""
    global should_stop
    
    # ì„¤ì • ë¡œë“œ
    bot_config = load_bot_config()
    rest_minutes = bot_config.get("rest_minutes", 3)
    print(f"[í¬ë¡¤ëŸ¬] ë°˜ìë™ ëª¨ë“œ - ëŒ“ê¸€ ìƒì„±ë§Œ í•˜ê³  ì‹¤ì œ ê²Œì‹œí•˜ì§€ ì•ŠìŒ")
    
    chrome_options = Options()
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)
    
    # ì„œë²„ìš© Headless ì˜µì…˜
    if HEADLESS_MODE:
        print("[ë´‡] Headless ëª¨ë“œë¡œ ì‹¤í–‰")
        
        # PID ê¸°ë°˜ ê³ ìœ  user-data-dir ìƒì„± (Chrome crash ë°©ì§€)
        user_data_dir = os.path.join(SCRIPT_DIR, f"chrome_data_{os.getpid()}")
        os.makedirs(user_data_dir, exist_ok=True)
        print(f"[ë´‡] Chrome user-data-dir: {user_data_dir}")
        
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--disable-software-rasterizer")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-setuid-sandbox")
        chrome_options.add_argument(f"--user-data-dir={user_data_dir}")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--disable-features=VizDisplayCompositor")
        chrome_options.add_argument("--disable-background-networking")
        chrome_options.add_argument("--disable-default-apps")
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    else:
        chrome_options.add_argument("--start-maximized")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    wait = WebDriverWait(driver, 10) 

    try:
        print("========== [ìë™ ëŒ“ê¸€ ë´‡ (ì„œë²„ìš©)] ==========")
        visited_links = load_history()
        
        # ì¿ í‚¤ ê¸°ë°˜ ë¡œê·¸ì¸
        if not load_cookies(driver):
            print("[ë´‡] ë¡œê·¸ì¸ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        print("[í¬ë¡¤ëŸ¬] ë´‡ ì‹œì‘! (ì¢…ë£Œ: Ctrl+C ë˜ëŠ” .stop_bot íŒŒì¼ ìƒì„±)")
        print("=" * 60)
        print("[ë°˜ìë™ ëª¨ë“œ] ëŒ“ê¸€ì„ ìƒì„±í•˜ì—¬ ëŒ€ê¸°ì—´ì— ì €ì¥í•©ë‹ˆë‹¤")
        print("=" * 60)

        while not should_stop:
            # ì¢…ë£Œ í”Œë˜ê·¸ í™•ì¸
            if check_stop_flag():
                print("[ë´‡] ì •ì§€ í”Œë˜ê·¸ ê°ì§€, ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # ì„¤ì • ë¦¬ë¡œë“œ (ëŸ°íƒ€ì„ ë³€ê²½ ë°˜ì˜)
            bot_config = load_bot_config()
            rest_minutes = bot_config.get("rest_minutes", 3)
            
            # ê²€ìƒ‰í•  ê²Œì‹œíŒ(ë©”ë‰´) ID: ì—†ìœ¼ë©´ ì „ì²´(0)
            menu_ids = getattr(config, "CAFE_MENU_IDS", None) or [0]
            if not menu_ids:
                menu_ids = [0]
            
            # í‚¤ì›Œë“œ ë¡œë“œ (ë§¤ ì‚¬ì´í´ë§ˆë‹¤ ìƒˆë¡œ ë¡œë“œí•˜ì—¬ ì‹¤ì‹œê°„ ë°˜ì˜)
            keywords = load_keywords()
            print(f"[INFO] ê²€ìƒ‰ í‚¤ì›Œë“œ {len(keywords)}ê°œ ë¡œë“œë¨")
            
            # ì „ì²´ê¸€ë³´ê¸°ì—ì„œë§Œ ê²€ìƒ‰ (menu_id=0)
            for keyword in keywords:
                if should_stop or check_stop_flag():
                    break
                    
                try:
                    encoded = urllib.parse.quote(keyword)
                    search_url = f"https://cafe.naver.com/f-e/cafes/{config.CLUB_ID}/menus/0?viewType=L&ta=ARTICLE_COMMENT&page=1&q={encoded}"
                    
                    print(f"\n>>> ì „ì²´ê¸€ë³´ê¸° / í‚¤ì›Œë“œ: '{keyword}'")
                    driver.get(search_url)
                    time.sleep(random.uniform(1, 2))  # ë¹ ë¥¸ í¬ë¡¤ë§
                    
                    all_links = driver.find_elements(By.XPATH, "//a[contains(@href, '/articles/') and not(contains(@class, 'comment'))]")
                    
                    if not all_links: continue

                    target_links = []
                    for a_tag in all_links[:50]:  # 50ê°œ ê¸€ íƒìƒ‰
                        try:
                            raw_link = a_tag.get_attribute('href')
                            clean_link = raw_link.split('?')[0] if '?' in raw_link else raw_link
                            title = a_tag.text.strip()
                            if len(title) > 1: 
                                target_links.append((clean_link, title))
                        except: continue
                    
                    print(f" -> ëŒ€ìƒ(ì¤‘ë³µí¬í•¨): {len(target_links)}ê°œ")

                    for link, title in target_links:
                        if should_stop or check_stop_flag():
                            break
                            
                        if link in visited_links:
                            print(f" -> [Skip] ë°©ê¸ˆ ì²˜ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. ({title[:10]}...)")
                            continue
                        
                        # ì¶”ê°€ ì¤‘ë³µ ì²´í¬: comment_history.jsonì—ì„œë„ í™•ì¸
                        if is_already_commented(link):
                            print(f" -> [Skip] ì´ë¯¸ ëŒ“ê¸€ ë‹¨ ê¸€ì…ë‹ˆë‹¤. ({title[:10]}...)")
                            visited_links.add(link)
                            continue
                        
                        try:
                            print(f"\n[ë¶„ì„] {title[:15]}...")
                            driver.get(link)
                            time.sleep(random.uniform(1, 2))  # ë¹ ë¥¸ í¬ë¡¤ë§
                            
                            try: driver.switch_to.frame("cafe_main")
                            except: pass

                            content = ""
                            try: content = driver.find_element(By.CSS_SELECTOR, "div.se-main-container").text
                            except:
                                try: content = driver.find_element(By.CSS_SELECTOR, "div.ContentRenderer").text
                                except: content = ""
                            
                            result = analyze_and_generate_reply(title, content)
                            
                            if result is None:
                                print("  -> [PASS] (í•©ê²©ì/ê´‘ê³ /ë¬´ê´€í•¨)")
                                append_history(link)
                                visited_links.add(link)
                                driver.switch_to.default_content()
                                continue
                            
                            ai_reply, extra = result
                            print(f"  -> [ì‘ì„±] {ai_reply[:50]}...")

                            try:
                                # ë°˜ìë™ ëª¨ë“œ: ëŒ“ê¸€ì„ ì‹¤ì œë¡œ ë‹¬ì§€ ì•Šê³  pending ìƒíƒœë¡œ ì €ì¥
                                print("  -> [ëŒ€ê¸°ì—´ ì¶”ê°€] ëŒ“ê¸€ ìƒì„± ì™„ë£Œ (ìŠ¹ì¸ ëŒ€ê¸°)")
                                print(f"     ìƒì„±ëœ ëŒ“ê¸€: {ai_reply[:100]}...")
                                # íˆìŠ¤í† ë¦¬ì— pending ìƒíƒœë¡œ ì €ì¥
                                append_history(link)
                                visited_links.add(link)
                                save_comment_history(link, title, ai_reply, success=True, status="pending", **extra)

                            except Exception as e:
                                print(f"  -> [ì‹¤íŒ¨] {e}")
                                save_comment_history(link, title, ai_reply, success=False, status="pending", **extra)

                            driver.switch_to.default_content()

                        except Exception as e:
                            print(f"  -> [ì—ëŸ¬] {e}")
                            driver.switch_to.default_content()
                            time.sleep(2)

                except Exception as e:
                    err_msg = str(e)
                    print(f"  -> [í‚¤ì›Œë“œ ì—ëŸ¬] {err_msg[:100]}")
                    # Chrome í¬ë˜ì‹œ ê°ì§€ ì‹œ ì¬ì‹œì‘
                    if "Connection refused" in err_msg or "invalid session" in err_msg.lower():
                        print("[ê²½ê³ ] Chrome í¬ë˜ì‹œ ê°ì§€! ë¸Œë¼ìš°ì € ì¬ì‹œì‘...")
                        try:
                            driver.quit()
                        except:
                            pass
                        # ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘
                        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
                        wait = WebDriverWait(driver, 10)
                        if not load_cookies(driver):
                            print("[ì—ëŸ¬] ì¬ë¡œê·¸ì¸ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            return
                        print("[ë³µêµ¬] ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì™„ë£Œ!")
            
            if should_stop:
                break
            
            # í¬ë¡¤ëŸ¬ ëª¨ë“œ: ì§§ì€ íœ´ì‹ í›„ ë‹¤ìŒ ì‚¬ì´í´
            print(f">>> íœ´ì‹ {rest_minutes}ë¶„...")
            for _ in range(rest_minutes * 6):  # 10ì´ˆ ë‹¨ìœ„ë¡œ ì²´í¬
                if should_stop or check_stop_flag():
                    break
                time.sleep(10)

    except KeyboardInterrupt:
        print("\n[í¬ë¡¤ëŸ¬] ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\n[í¬ë¡¤ëŸ¬] ì˜ˆì™¸ ë°œìƒ: {e}")
    finally:
        print("[í¬ë¡¤ëŸ¬] ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
        driver.quit()
        
        # Headless ëª¨ë“œì—ì„œ user-data-dir ì •ë¦¬
        if HEADLESS_MODE:
            user_data_dir = os.path.join(SCRIPT_DIR, f"chrome_data_{os.getpid()}")
            if os.path.exists(user_data_dir):
                try:
                    import shutil
                    shutil.rmtree(user_data_dir)
                    print(f"[í¬ë¡¤ëŸ¬] Chrome user-data-dir ì •ë¦¬ ì™„ë£Œ: {user_data_dir}")
                except Exception as e:
                    print(f"[í¬ë¡¤ëŸ¬] Chrome user-data-dir ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        print("[í¬ë¡¤ëŸ¬] ì¢…ë£Œ ì™„ë£Œ")


# ==========================================
# [ê²Œì‹œ ì›Œì»¤] - ìŠ¹ì¸ëœ ëŒ“ê¸€ë§Œ ë”œë ˆì´ ì ìš©í•˜ì—¬ ì‹¤ì œ ê²Œì‹œ
# ==========================================
POSTER_STOP_FLAG_FILE = os.path.join(SCRIPT_DIR, ".stop_poster")
poster_should_stop = False

def check_poster_stop_flag():
    """ê²Œì‹œ ì›Œì»¤ ì •ì§€ í”Œë˜ê·¸ íŒŒì¼ í™•ì¸"""
    if os.path.exists(POSTER_STOP_FLAG_FILE):
        os.remove(POSTER_STOP_FLAG_FILE)
        return True
    return False

def load_approved_comments():
    """ìŠ¹ì¸ëœ ëŒ“ê¸€ ëª©ë¡ ë¡œë“œ"""
    if not os.path.exists(COMMENT_HISTORY_FILE):
        return []
    try:
        with open(COMMENT_HISTORY_FILE, "r", encoding="utf-8") as f:
            history = json.load(f)
            return [c for c in history if c.get("status") == "approved"]
    except:
        return []

def update_comment_status(comment_id, new_status, posted_at=None):
    """ëŒ“ê¸€ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    if not os.path.exists(COMMENT_HISTORY_FILE):
        return False
    try:
        with open(COMMENT_HISTORY_FILE, "r", encoding="utf-8") as f:
            history = json.load(f)
        
        for comment in history:
            if comment.get("id") == comment_id:
                comment["status"] = new_status
                if posted_at:
                    comment["posted_at"] = posted_at
                # action_historyì— ì¶”ê°€
                if "action_history" not in comment:
                    comment["action_history"] = []
                comment["action_history"].append({
                    "action": new_status,
                    "timestamp": datetime.now().isoformat()
                })
                break
        
        with open(COMMENT_HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"[ê²Œì‹œì›Œì»¤] ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def run_poster_bot():
    """ê²Œì‹œ ì›Œì»¤: ìŠ¹ì¸ëœ ëŒ“ê¸€ë§Œ ë”œë ˆì´ ì ìš©í•˜ì—¬ ì‹¤ì œ ê²Œì‹œ"""
    global poster_should_stop
    poster_should_stop = False
    
    # ì„¤ì • ë¡œë“œ
    bot_config = load_bot_config()
    min_delay_sec = bot_config.get("min_delay_seconds", 50)
    cph_min = bot_config.get("comments_per_hour_min", 5)
    cph_max = bot_config.get("comments_per_hour_max", 10)
    
    print(f"[ê²Œì‹œì›Œì»¤] ì‹œì‘ - ì‹œê°„ë‹¹ {cph_min}~{cph_max}ê°œ ëŒ“ê¸€ ê²Œì‹œ")
    
    chrome_options = Options()
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)
    
    if HEADLESS_MODE:
        print("[ê²Œì‹œì›Œì»¤] Headless ëª¨ë“œë¡œ ì‹¤í–‰")
        user_data_dir = os.path.join(SCRIPT_DIR, f"chrome_poster_{os.getpid()}")
        os.makedirs(user_data_dir, exist_ok=True)
        
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument(f"--user-data-dir={user_data_dir}")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
    else:
        chrome_options.add_argument("--start-maximized")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    wait = WebDriverWait(driver, 10)
    
    try:
        # ì¿ í‚¤ ê¸°ë°˜ ë¡œê·¸ì¸
        if not load_cookies(driver):
            print("[ê²Œì‹œì›Œì»¤] ë¡œê·¸ì¸ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        print("[ê²Œì‹œì›Œì»¤] ë¡œê·¸ì¸ ì„±ê³µ! ìŠ¹ì¸ëœ ëŒ“ê¸€ ê²Œì‹œ ì‹œì‘...")
        
        while not poster_should_stop:
            if check_poster_stop_flag():
                print("[ê²Œì‹œì›Œì»¤] ì •ì§€ í”Œë˜ê·¸ ê°ì§€, ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # ìŠ¹ì¸ëœ ëŒ“ê¸€ ë¡œë“œ
            approved_comments = load_approved_comments()
            
            if not approved_comments:
                print("[ê²Œì‹œì›Œì»¤] ìŠ¹ì¸ëœ ëŒ“ê¸€ ì—†ìŒ. 30ì´ˆ í›„ ì¬í™•ì¸...")
                for _ in range(6):  # 5ì´ˆ ë‹¨ìœ„ë¡œ ì²´í¬
                    if poster_should_stop or check_poster_stop_flag():
                        break
                    time.sleep(5)
                continue
            
            print(f"[ê²Œì‹œì›Œì»¤] ìŠ¹ì¸ëœ ëŒ“ê¸€ {len(approved_comments)}ê°œ ë°œê²¬")
            
            for comment in approved_comments:
                if poster_should_stop or check_poster_stop_flag():
                    break
                
                comment_id = comment.get("id")
                post_url = comment.get("post_url")
                ai_reply = comment.get("comment")
                title = comment.get("post_title", "")[:20]
                
                print(f"\n[ê²Œì‹œ] {title}... -> {post_url[:50]}...")
                
                try:
                    # URL í˜•ì‹ ë³€í™˜: /f-e/cafes/... í˜•ì‹ì„ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    import re
                    converted_url = post_url
                    fe_match = re.search(r'/f-e/cafes/\d+/articles/(\d+)', post_url)
                    if fe_match:
                        article_id = fe_match.group(1)
                        # configì—ì„œ ì¹´í˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                        converted_url = f"https://cafe.naver.com/{config.CAFE_NAME}/{article_id}"
                        print(f"  -> URL ë³€í™˜: {converted_url}")
                    
                    driver.get(converted_url)
                    time.sleep(3)
                    
                    # iframe ì „í™˜
                    try:
                        driver.switch_to.frame("cafe_main")
                    except:
                        pass
                    
                    # ëŒ“ê¸€ ì…ë ¥ (ì´ì „ ì‘ë™ ì½”ë“œì™€ ë™ì¼)
                    inbox = wait.until(EC.presence_of_element_located((By.CLASS_NAME, "comment_inbox")))
                    driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", inbox)
                    inbox.click()
                    time.sleep(1)
                    
                    try:
                        driver.find_element(By.CLASS_NAME, "comment_inbox_text").send_keys(ai_reply)
                    except:
                        driver.switch_to.active_element.send_keys(ai_reply)
                    
                    time.sleep(1)
                    driver.find_element(By.XPATH, "//*[text()='ë“±ë¡']").click()
                    
                    # Alert ì²˜ë¦¬
                    try:
                        WebDriverWait(driver, 2).until(EC.alert_is_present())
                        driver.switch_to.alert.accept()
                        print(f"  -> [ì‹¤íŒ¨] Alert ë°œìƒ")
                        update_comment_status(comment_id, "failed")
                        driver.switch_to.default_content()
                        continue
                    except:
                        pass
                    
                    print(f"  -> [ê²Œì‹œ ì™„ë£Œ]")
                    update_comment_status(comment_id, "posted", posted_at=datetime.now().isoformat())
                    
                    driver.switch_to.default_content()
                    
                    # ë”œë ˆì´ ì ìš©
                    bot_config = load_bot_config()
                    min_delay_sec = bot_config.get("min_delay_seconds", 50)
                    cph_min = bot_config.get("comments_per_hour_min", 5)
                    cph_max = bot_config.get("comments_per_hour_max", 10)
                    
                    if cph_min and cph_max and 0 < cph_min <= cph_max:
                        d_max = 3600 / cph_min
                        d_min_cand = 3600 / cph_max
                        d_min = max(min_delay_sec, d_min_cand)
                        d_min = min(d_min, d_max - 1) if d_min >= d_max else d_min
                        d_max = max(d_max, d_min + 1)
                    else:
                        d_min, d_max = min_delay_sec, 720
                    
                    delay = random.uniform(d_min, d_max)
                    print(f"  -> ë‹¤ìŒ ëŒ“ê¸€ê¹Œì§€ {delay:.0f}ì´ˆ ëŒ€ê¸°...")
                    
                    # ëŒ€ê¸° ì¤‘ì—ë„ ì¢…ë£Œ í”Œë˜ê·¸ í™•ì¸
                    for _ in range(int(delay / 5)):
                        if poster_should_stop or check_poster_stop_flag():
                            break
                        time.sleep(5)
                    
                except Exception as e:
                    print(f"  -> [ì—ëŸ¬] {type(e).__name__}: {str(e)[:200]}")
                    import traceback
                    traceback.print_exc()
                    update_comment_status(comment_id, "failed")
                    driver.switch_to.default_content()
                    time.sleep(2)
    
    except KeyboardInterrupt:
        print("\n[ê²Œì‹œì›Œì»¤] ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\n[ê²Œì‹œì›Œì»¤] ì˜ˆì™¸ ë°œìƒ: {e}")
    finally:
        print("[ê²Œì‹œì›Œì»¤] ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
        driver.quit()
        
        if HEADLESS_MODE:
            user_data_dir = os.path.join(SCRIPT_DIR, f"chrome_poster_{os.getpid()}")
            if os.path.exists(user_data_dir):
                try:
                    import shutil
                    shutil.rmtree(user_data_dir)
                except:
                    pass
        
        print("[ê²Œì‹œì›Œì»¤] ì¢…ë£Œ ì™„ë£Œ")

if __name__ == "__main__":
    run_search_bot()